{
 "cells": [
  {
   "source": [
    "## 读入分析数据"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-02T09:54:03.520380Z",
     "start_time": "2020-11-02T09:54:03.516392Z"
    }
   },
   "outputs": [],
   "source": [
    "# numpy and pandas for data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "# sklearn preprocessing for dealing with categorical variables\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, MaxAbsScaler, StandardScaler\n",
    "from sklearn.impute import SimpleImputer as Imputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# File system manangement\n",
    "import os\n",
    "\n",
    "import joblib\n",
    "import requests\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-02T09:54:37.378241Z",
     "start_time": "2020-11-02T09:54:37.370262Z"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['application_test.csv', 'application_train.csv', 'bureau.csv', 'bureau_balance.csv', 'credit_card_balance.csv', 'HomeCredit_columns_description.csv', 'installments_payments.csv', 'POS_CASH_balance.csv', 'previous_application.csv', 'sample_submission.csv']\n"
     ]
    }
   ],
   "source": [
    "# List files available\n",
    "print(os.listdir(\"./input/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-02T09:55:00.329493Z",
     "start_time": "2020-11-02T09:54:56.606423Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training data shape:  (307511, 122)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   SK_ID_CURR  TARGET NAME_CONTRACT_TYPE CODE_GENDER FLAG_OWN_CAR  \\\n",
       "0      100002       1         Cash loans           M            N   \n",
       "1      100003       0         Cash loans           F            N   \n",
       "2      100004       0    Revolving loans           M            Y   \n",
       "3      100006       0         Cash loans           F            N   \n",
       "4      100007       0         Cash loans           M            N   \n",
       "\n",
       "  FLAG_OWN_REALTY  CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY  \\\n",
       "0               Y             0          202500.0    406597.5      24700.5   \n",
       "1               N             0          270000.0   1293502.5      35698.5   \n",
       "2               Y             0           67500.0    135000.0       6750.0   \n",
       "3               Y             0          135000.0    312682.5      29686.5   \n",
       "4               Y             0          121500.0    513000.0      21865.5   \n",
       "\n",
       "   ...  FLAG_DOCUMENT_18 FLAG_DOCUMENT_19 FLAG_DOCUMENT_20 FLAG_DOCUMENT_21  \\\n",
       "0  ...                 0                0                0                0   \n",
       "1  ...                 0                0                0                0   \n",
       "2  ...                 0                0                0                0   \n",
       "3  ...                 0                0                0                0   \n",
       "4  ...                 0                0                0                0   \n",
       "\n",
       "  AMT_REQ_CREDIT_BUREAU_HOUR AMT_REQ_CREDIT_BUREAU_DAY  \\\n",
       "0                        0.0                       0.0   \n",
       "1                        0.0                       0.0   \n",
       "2                        0.0                       0.0   \n",
       "3                        NaN                       NaN   \n",
       "4                        0.0                       0.0   \n",
       "\n",
       "   AMT_REQ_CREDIT_BUREAU_WEEK  AMT_REQ_CREDIT_BUREAU_MON  \\\n",
       "0                         0.0                        0.0   \n",
       "1                         0.0                        0.0   \n",
       "2                         0.0                        0.0   \n",
       "3                         NaN                        NaN   \n",
       "4                         0.0                        0.0   \n",
       "\n",
       "   AMT_REQ_CREDIT_BUREAU_QRT  AMT_REQ_CREDIT_BUREAU_YEAR  \n",
       "0                        0.0                         1.0  \n",
       "1                        0.0                         0.0  \n",
       "2                        0.0                         0.0  \n",
       "3                        NaN                         NaN  \n",
       "4                        0.0                         0.0  \n",
       "\n",
       "[5 rows x 122 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SK_ID_CURR</th>\n      <th>TARGET</th>\n      <th>NAME_CONTRACT_TYPE</th>\n      <th>CODE_GENDER</th>\n      <th>FLAG_OWN_CAR</th>\n      <th>FLAG_OWN_REALTY</th>\n      <th>CNT_CHILDREN</th>\n      <th>AMT_INCOME_TOTAL</th>\n      <th>AMT_CREDIT</th>\n      <th>AMT_ANNUITY</th>\n      <th>...</th>\n      <th>FLAG_DOCUMENT_18</th>\n      <th>FLAG_DOCUMENT_19</th>\n      <th>FLAG_DOCUMENT_20</th>\n      <th>FLAG_DOCUMENT_21</th>\n      <th>AMT_REQ_CREDIT_BUREAU_HOUR</th>\n      <th>AMT_REQ_CREDIT_BUREAU_DAY</th>\n      <th>AMT_REQ_CREDIT_BUREAU_WEEK</th>\n      <th>AMT_REQ_CREDIT_BUREAU_MON</th>\n      <th>AMT_REQ_CREDIT_BUREAU_QRT</th>\n      <th>AMT_REQ_CREDIT_BUREAU_YEAR</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>100002</td>\n      <td>1</td>\n      <td>Cash loans</td>\n      <td>M</td>\n      <td>N</td>\n      <td>Y</td>\n      <td>0</td>\n      <td>202500.0</td>\n      <td>406597.5</td>\n      <td>24700.5</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>100003</td>\n      <td>0</td>\n      <td>Cash loans</td>\n      <td>F</td>\n      <td>N</td>\n      <td>N</td>\n      <td>0</td>\n      <td>270000.0</td>\n      <td>1293502.5</td>\n      <td>35698.5</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>100004</td>\n      <td>0</td>\n      <td>Revolving loans</td>\n      <td>M</td>\n      <td>Y</td>\n      <td>Y</td>\n      <td>0</td>\n      <td>67500.0</td>\n      <td>135000.0</td>\n      <td>6750.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>100006</td>\n      <td>0</td>\n      <td>Cash loans</td>\n      <td>F</td>\n      <td>N</td>\n      <td>Y</td>\n      <td>0</td>\n      <td>135000.0</td>\n      <td>312682.5</td>\n      <td>29686.5</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>100007</td>\n      <td>0</td>\n      <td>Cash loans</td>\n      <td>M</td>\n      <td>N</td>\n      <td>Y</td>\n      <td>0</td>\n      <td>121500.0</td>\n      <td>513000.0</td>\n      <td>21865.5</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 122 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "# Training data\n",
    "app_train = pd.read_csv('./input/application_train.csv')\n",
    "app_test = pd.read_csv('./input/application_test.csv')\n",
    "bureau = pd.read_csv('./input/bureau.csv')\n",
    "bb = pd.read_csv('./input/bureau_balance.csv')\n",
    "prev = pd.read_csv('./input/previous_application.csv')\n",
    "cc = pd.read_csv('./input/credit_card_balance.csv')\n",
    "ins = pd.read_csv('./input/installments_payments.csv')\n",
    "pos = pd.read_csv('./input/POS_CASH_balance.csv')\n",
    "\n",
    "\n",
    "dic={}\n",
    "dic['bur'] = bureau\n",
    "dic['bb'] = bb\n",
    "dic['pre'] = prev\n",
    "dic['cc'] = cc\n",
    "dic['ins'] = ins\n",
    "dic['pos'] = pos\n",
    "\n",
    "print('Training data shape: ', app_train.shape)\n",
    "app_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Features shape:  (307511, 121)\nTesting Features shape:  (48744, 121)\n"
     ]
    }
   ],
   "source": [
    "train_labels = app_train['TARGET']\n",
    "\n",
    "app_train, app_test = app_train.align(app_test, join = 'inner', axis = 1)\n",
    "print('Training Features shape: ', app_train.shape)\n",
    "print('Testing Features shape: ', app_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# numeric_columns = []\n",
    "# category_columns = []\n",
    "\n",
    "# for col in app_train:\n",
    "\n",
    "#     if app_train[col].isna().sum() > 0.7 * app_train.shape[0]:\n",
    "#         continue\n",
    "\n",
    "#     if app_train[col].dtype == ('object') or app_train[col].dtype == ('bool'):\n",
    "#         category_columns.append(col)\n",
    "#     else:\n",
    "#         numeric_columns.append(col)\n",
    "\n",
    "# print(\"Number of categorical feature:\", len(category_columns))\n",
    "# print(\"Number of numerical feature:\", len(numeric_columns))\n",
    "# print(\"Number of missing feature:\", app_train.shape[1] - len(category_columns) - len(numeric_columns))"
   ]
  },
  {
   "source": [
    "## 预处理"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding for categorical columns with get_dummies\n",
    "def one_hot_encoder(df, nan_as_category = True):\n",
    "    original_columns = list(df.columns)\n",
    "    categorical_columns = [col for col in df.columns if ((df[col].dtype == 'object') or (df[col].dtype == 'bool'))]\n",
    "    df = pd.get_dummies(df, columns= categorical_columns, dummy_na= nan_as_category)\n",
    "    new_columns = [c for c in df.columns if c not in original_columns]\n",
    "    return df, new_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    " \n",
    "class appTrainTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        return None\n",
    " \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    " \n",
    "    def transform(self, X, y=None):\n",
    "        # DAYS_EMPLOYED_anom\n",
    "        X['DAYS_EMPLOYED_anom'] = (X['DAYS_EMPLOYED'] == 365243)\n",
    "        X['DAYS_EMPLOYED'].replace(365243, np.nan, inplace = True)\n",
    "\n",
    "        # Some simple new features (percentages)\n",
    "        X['DAYS_EMPLOYED_PERC'] = X['DAYS_EMPLOYED'] / X['DAYS_BIRTH']\n",
    "        X['INCOME_CREDIT_PERC'] = X['AMT_INCOME_TOTAL'] / X['AMT_CREDIT']\n",
    "        X['INCOME_PER_PERSON'] = X['AMT_INCOME_TOTAL'] / X['CNT_FAM_MEMBERS']\n",
    "        X['ANNUITY_INCOME_PERC'] = X['AMT_ANNUITY'] / X['AMT_INCOME_TOTAL']\n",
    "        X['PAYMENT_RATE'] = X['AMT_ANNUITY'] / X['AMT_CREDIT']\n",
    "        X.replace(np.inf, np.nan, inplace = True)\n",
    "\n",
    "        return X\n",
    "\n",
    "class dropTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, rate):\n",
    "        self.rate = rate\n",
    "        self.drop = []\n",
    "        return None\n",
    " \n",
    "    def fit(self, X, y=None):\n",
    "        drop = []\n",
    "        for col in X:\n",
    "            if X[col].isna().sum() > self.rate * X.shape[0]:\n",
    "                drop.append(col)\n",
    "        self.drop = drop\n",
    "        return self\n",
    " \n",
    "    def transform(self, X_copy, y=None):\n",
    "        X_copy.drop(self.drop, axis = 1, inplace = True)\n",
    "        return X_copy\n",
    "\n",
    "class bureauTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        return None\n",
    " \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    " \n",
    "    def transform(self, bureauinfo, bbinfo, y=None):\n",
    "        # app_train treatment\n",
    "        bb_copy, bb_cat = one_hot_encoder(bbinfo, True)\n",
    "        bureau_copy, bureau_cat = one_hot_encoder(bureauinfo, True)\n",
    "\n",
    "        # bb Treatment\n",
    "        bb_aggregations = {'MONTHS_BALANCE': ['min', 'max', 'size']}\n",
    "        for col in bb_cat:\n",
    "            bb_aggregations[col] = ['mean']\n",
    "        bb_agg = bb_copy.groupby('SK_ID_BUREAU').agg(bb_aggregations)\n",
    "        bb_agg.columns = pd.Index([e[0] + \"_\" + e[1].upper() for e in bb_agg.columns.tolist()])\n",
    "        bureau_copy = bureau_copy.join(bb_agg, how='left', on='SK_ID_BUREAU')\n",
    "        bureau_copy.drop(['SK_ID_BUREAU'], axis=1, inplace= True)\n",
    "\n",
    "        ## bureau Treatment\n",
    "        # Bureau and bureau_balance numeric features\n",
    "        num_aggregations = {\n",
    "            'DAYS_CREDIT': ['min', 'max', 'mean', 'var'],\n",
    "            'DAYS_CREDIT_ENDDATE': ['min', 'max', 'mean'],\n",
    "            'DAYS_CREDIT_UPDATE': ['mean'],\n",
    "            'CREDIT_DAY_OVERDUE': ['max', 'mean'],\n",
    "            'AMT_CREDIT_MAX_OVERDUE': ['mean'],\n",
    "            'AMT_CREDIT_SUM': ['max', 'mean', 'sum'],\n",
    "            'AMT_CREDIT_SUM_DEBT': ['max', 'mean', 'sum'],\n",
    "            'AMT_CREDIT_SUM_OVERDUE': ['mean'],\n",
    "            'AMT_CREDIT_SUM_LIMIT': ['mean', 'sum'],\n",
    "            'AMT_ANNUITY': ['max', 'mean'],\n",
    "            'CNT_CREDIT_PROLONG': ['sum'],\n",
    "            'MONTHS_BALANCE_MIN': ['min'],\n",
    "            'MONTHS_BALANCE_MAX': ['max'],\n",
    "            'MONTHS_BALANCE_SIZE': ['mean', 'sum']\n",
    "        }\n",
    "\n",
    "        # Bureau and bureau_balance categorical features\n",
    "        cat_aggregations = {}\n",
    "        for cat in bureau_cat: \n",
    "            cat_aggregations[cat] = ['mean']\n",
    "        for cat in bb_cat: \n",
    "            cat_aggregations[cat + \"_MEAN\"] = ['mean']\n",
    "\n",
    "        bureau_agg = bureau_copy.groupby('SK_ID_CURR').agg({**num_aggregations, **cat_aggregations})\n",
    "        bureau_agg.columns = pd.Index(['BURO_' + e[0] + \"_\" + e[1].upper() for e in bureau_agg.columns.tolist()])\n",
    "\n",
    "        # Bureau: Active credits - using only numerical aggregations\n",
    "        active = bureau_copy[bureau_copy['CREDIT_ACTIVE_Active'] == 1]\n",
    "        active_agg = active.groupby('SK_ID_CURR').agg(num_aggregations)\n",
    "        active_agg.columns = pd.Index(['ACTIVE_' + e[0] + \"_\" + e[1].upper() for e in active_agg.columns.tolist()])\n",
    "        bureau_agg = bureau_agg.join(active_agg, how='left', on='SK_ID_CURR')\n",
    "\n",
    "\n",
    "        # Bureau: Closed credits - using only numerical aggregations\n",
    "        closed = bureau_copy[bureau_copy['CREDIT_ACTIVE_Closed'] == 1]\n",
    "        closed_agg = closed.groupby('SK_ID_CURR').agg(num_aggregations)\n",
    "        closed_agg.columns = pd.Index(['CLOSED_' + e[0] + \"_\" + e[1].upper() for e in closed_agg.columns.tolist()])\n",
    "        bureau_agg = bureau_agg.join(closed_agg, how='left', on='SK_ID_CURR')\n",
    "\n",
    "        return bureau_agg\n",
    "\n",
    "class previousTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        return None\n",
    " \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    " \n",
    "    def transform(self, previnfo, y=None):\n",
    "\n",
    "        prev, cat_cols = one_hot_encoder(previnfo, nan_as_category= True)\n",
    "        # Days 365.243 values -> nan\n",
    "        prev['DAYS_FIRST_DRAWING'].replace(365243, np.nan, inplace= True)\n",
    "        prev['DAYS_FIRST_DUE'].replace(365243, np.nan, inplace= True)\n",
    "        prev['DAYS_LAST_DUE_1ST_VERSION'].replace(365243, np.nan, inplace= True)\n",
    "        prev['DAYS_LAST_DUE'].replace(365243, np.nan, inplace= True)\n",
    "        prev['DAYS_TERMINATION'].replace(365243, np.nan, inplace= True)\n",
    "\n",
    "        # Add feature: value ask / value received percentage\n",
    "        prev['APP_CREDIT_PERC'] = prev['AMT_APPLICATION'] / prev['AMT_CREDIT']\n",
    "        # Previous applications numeric features\n",
    "        num_aggregations = {\n",
    "            'AMT_ANNUITY': ['min', 'max', 'mean'],\n",
    "            'AMT_APPLICATION': ['min', 'max', 'mean'],\n",
    "            'AMT_CREDIT': ['min', 'max', 'mean'],\n",
    "            'APP_CREDIT_PERC': ['min', 'max', 'mean', 'var'],\n",
    "            'AMT_DOWN_PAYMENT': ['min', 'max', 'mean'],\n",
    "            'AMT_GOODS_PRICE': ['min', 'max', 'mean'],\n",
    "            'HOUR_APPR_PROCESS_START': ['min', 'max', 'mean'],\n",
    "            'RATE_DOWN_PAYMENT': ['min', 'max', 'mean'],\n",
    "            'DAYS_DECISION': ['min', 'max', 'mean'],\n",
    "            'CNT_PAYMENT': ['mean', 'sum'],\n",
    "        }\n",
    "        # Previous applications categorical features\n",
    "        cat_aggregations = {}\n",
    "        for cat in cat_cols:\n",
    "            cat_aggregations[cat] = ['mean']\n",
    "        \n",
    "        prev_agg = prev.groupby('SK_ID_CURR').agg({**num_aggregations, **cat_aggregations})\n",
    "        prev_agg.columns = pd.Index(['PREV_' + e[0] + \"_\" + e[1].upper() for e in prev_agg.columns.tolist()])\n",
    "        # Previous Applications: Approved Applications - only numerical features\n",
    "        approved = prev[prev['NAME_CONTRACT_STATUS_Approved'] == 1]\n",
    "        approved_agg = approved.groupby('SK_ID_CURR').agg(num_aggregations)\n",
    "        approved_agg.columns = pd.Index(['APPROVED_' + e[0] + \"_\" + e[1].upper() for e in approved_agg.columns.tolist()])\n",
    "        prev_agg = prev_agg.join(approved_agg, how='left', on='SK_ID_CURR')\n",
    "        # Previous Applications: Refused Applications - only numerical features\n",
    "        refused = prev[prev['NAME_CONTRACT_STATUS_Refused'] == 1]\n",
    "        refused_agg = refused.groupby('SK_ID_CURR').agg(num_aggregations)\n",
    "        refused_agg.columns = pd.Index(['REFUSED_' + e[0] + \"_\" + e[1].upper() for e in refused_agg.columns.tolist()])\n",
    "        prev_agg = prev_agg.join(refused_agg, how='left', on='SK_ID_CURR')\n",
    "\n",
    "        return prev_agg\n",
    "\n",
    "class posTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        return None\n",
    " \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    " \n",
    "    def transform(self, posinfo, y=None):\n",
    "\n",
    "        pos, cat_cols = one_hot_encoder(posinfo, True)\n",
    "        # Features\n",
    "        aggregations = {\n",
    "            'MONTHS_BALANCE': ['max', 'mean', 'size'],\n",
    "            'SK_DPD': ['max', 'mean'],\n",
    "            'SK_DPD_DEF': ['max', 'mean']\n",
    "        }\n",
    "        for cat in cat_cols:\n",
    "            aggregations[cat] = ['mean']\n",
    "        \n",
    "        pos_agg = pos.groupby('SK_ID_CURR').agg(aggregations)\n",
    "        pos_agg.columns = pd.Index(['POS_' + e[0] + \"_\" + e[1].upper() for e in pos_agg.columns.tolist()])\n",
    "        # Count pos cash accounts\n",
    "        pos_agg['POS_COUNT'] = pos.groupby('SK_ID_CURR').size()\n",
    "\n",
    "        return pos_agg\n",
    "    \n",
    "class installmentsTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        return None\n",
    " \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    " \n",
    "    def transform(self, insinfo, y=None):\n",
    "        ins, cat_cols = one_hot_encoder(insinfo, True)\n",
    "\n",
    "        # Percentage and difference paid in each installment (amount paid and installment value)\n",
    "        ins['PAYMENT_PERC'] = ins['AMT_PAYMENT'] / ins['AMT_INSTALMENT']\n",
    "        ins['PAYMENT_DIFF'] = ins['AMT_INSTALMENT'] - ins['AMT_PAYMENT']\n",
    "        # Days past due and days before due (no negative values)\n",
    "        ins['DPD'] = ins['DAYS_ENTRY_PAYMENT'] - ins['DAYS_INSTALMENT']\n",
    "        ins['DBD'] = ins['DAYS_INSTALMENT'] - ins['DAYS_ENTRY_PAYMENT']\n",
    "        ins['DPD'] = ins['DPD'].apply(lambda x: x if x > 0 else 0)\n",
    "        ins['DBD'] = ins['DBD'].apply(lambda x: x if x > 0 else 0)\n",
    "        # Features: Perform aggregations\n",
    "        aggregations = {\n",
    "            'NUM_INSTALMENT_VERSION': ['nunique'],\n",
    "            'DPD': ['max', 'mean', 'sum'],\n",
    "            'DBD': ['max', 'mean', 'sum'],\n",
    "            'PAYMENT_PERC': ['max', 'mean', 'sum', 'var'],\n",
    "            'PAYMENT_DIFF': ['max', 'mean', 'sum', 'var'],\n",
    "            'AMT_INSTALMENT': ['max', 'mean', 'sum'],\n",
    "            'AMT_PAYMENT': ['min', 'max', 'mean', 'sum'],\n",
    "            'DAYS_ENTRY_PAYMENT': ['max', 'mean', 'sum']\n",
    "        }\n",
    "        for cat in cat_cols:\n",
    "            aggregations[cat] = ['mean']\n",
    "        ins_agg = ins.groupby('SK_ID_CURR').agg(aggregations)\n",
    "        ins_agg.columns = pd.Index(['INSTAL_' + e[0] + \"_\" + e[1].upper() for e in ins_agg.columns.tolist()])\n",
    "        # Count installments accounts\n",
    "        ins_agg['INSTAL_COUNT'] = ins.groupby('SK_ID_CURR').size()\n",
    "        return ins_agg\n",
    "\n",
    "class ccTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        return None\n",
    " \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    " \n",
    "    def transform(self, ccinfo, y=None):\n",
    "        cc, cat_cols = one_hot_encoder(ccinfo, True)\n",
    "        # General aggregations\n",
    "        cc.drop(['SK_ID_PREV'], axis= 1, inplace = True)\n",
    "        cc_agg = cc.groupby('SK_ID_CURR').agg(['min', 'max', 'mean', 'sum', 'var'])\n",
    "        cc_agg.columns = pd.Index(['CC_' + e[0] + \"_\" + e[1].upper() for e in cc_agg.columns.tolist()])\n",
    "        # Count credit card lines\n",
    "        cc_agg['CC_COUNT'] = cc.groupby('SK_ID_CURR').size()\n",
    "        return cc_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bur = bureauTransformer().transform(dic['bur'], dic['bb'])\n",
    "pre = previousTransformer().transform(dic['pre'])\n",
    "pos = posTransformer().transform(dic['pos'])\n",
    "cc = ccTransformer().transform(dic['cc'])\n",
    "ins = installmentsTransformer().transform(dic['ins'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join(X):\n",
    "    X = X.join(bur, how='left', on='SK_ID_CURR')\n",
    "    X = X.join(pre, how='left', on='SK_ID_CURR')\n",
    "    X = X.join(pos, how='left', on='SK_ID_CURR')\n",
    "    X = X.join(cc, how='left', on='SK_ID_CURR')\n",
    "    X = X.join(ins, how='left', on='SK_ID_CURR')\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of categorical feature: 17\nNumber of numerical feature: 484\n"
     ]
    }
   ],
   "source": [
    "X = app_train.copy()\n",
    "X = join(X)\n",
    "X = appTrainTransformer().transform(X)\n",
    "X = dropTransformer(0.7).fit_transform(X)\n",
    "\n",
    "\n",
    "numeric_columns = []\n",
    "category_columns = []\n",
    "\n",
    "for col in X:\n",
    "    \n",
    "    if X[col].dtype == ('object') or X[col].dtype == ('bool'):\n",
    "        category_columns.append(col)\n",
    "    else:\n",
    "        numeric_columns.append(col)\n",
    "\n",
    "print(\"Number of categorical feature:\", len(category_columns))\n",
    "print(\"Number of numerical feature:\", len(numeric_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('impute_nan', Imputer(missing_values=np.nan,strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "category_transformer = Pipeline(steps=[\n",
    "    ('impute', Imputer(strategy='constant', fill_value='missing')),\n",
    "    ('ohe', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocesser = ColumnTransformer(transformers=[\n",
    "    ('numeric', numeric_transformer, numeric_columns),\n",
    "    ('category', category_transformer, category_columns)\n",
    "]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_pre = Pipeline(steps=[\n",
    "    ('app', appTrainTransformer()),\n",
    "    ('drop', dropTransformer(0.7)),\n",
    "    ('preprocesser', preprocesser)\n",
    "])"
   ]
  },
  {
   "source": [
    "## 建造Pipeline"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_av_train = app_train.copy()\n",
    "app_av_train = join(app_av_train)\n",
    "\n",
    "app_av_test = app_test.copy()\n",
    "app_av_test = join(app_av_test)\n",
    "\n",
    "app_pre_train = pipeline_pre.fit_transform(app_av_train)\n",
    "app_pre_test = pipeline_pre.transform(app_av_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(app_pre_train, train_labels, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import lightgbm as lgb\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "estimators = [\n",
    "    ('rf', RandomForestClassifier(random_state=42)),\n",
    "    ('svr', LinearSVC(random_state=42)),\n",
    "    ('lr', LogisticRegression()),\n",
    "    ('lgbm', lgb.LGBMClassifier(\n",
    "                nthread=4,\n",
    "                n_estimators=1000,\n",
    "                learning_rate=0.02,\n",
    "                num_leaves=34,\n",
    "                colsample_bytree=0.9497036,\n",
    "                subsample=0.8715623,\n",
    "                max_depth=8,\n",
    "                reg_alpha=0.041545473,\n",
    "                reg_lambda=0.0735294,\n",
    "                min_split_gain=0.0222415,\n",
    "                min_child_weight=39.3259775,\n",
    "                silent=-1,\n",
    "                verbose=-1)) #,\n",
    "    # ('gb',GradientBoostingClassifier())\n",
    "]\n",
    "clf = StackingClassifier(\n",
    "    estimators=estimators, final_estimator=LogisticRegression()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "-4829.623666524887\n"
     ]
    }
   ],
   "source": [
    "# 使用sklearn的pipelines训练一个模型\n",
    "import time\n",
    "s = time.time()\n",
    "clf.fit(app_pre_train, train_labels)\n",
    "e = time.time()\n",
    "print(s-e)"
   ]
  },
  {
   "source": [
    "## Kaggle 输出 （用于上传） "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = clf.predict_proba(app_pre_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_pred = Y[:, 1]\n",
    "submit = app_test[['SK_ID_CURR']]\n",
    "submit['TARGET'] = log_reg_pred\n",
    "submit.to_csv('baseline.csv', index = False)"
   ]
  },
  {
   "source": [
    "## Pipeline Output"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['./preprocess_model.joblib']"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "joblib.dump(pipeline_pre, './preprocess_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['./clf.joblib']"
      ]
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "joblib.dump(clf, './clf.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('ICT_TP2': conda)",
   "metadata": {
    "interpreter": {
     "hash": "558a930abb17a758a0551b39992238abdc330d323f5c283a9ea65ae5bef6161a"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}