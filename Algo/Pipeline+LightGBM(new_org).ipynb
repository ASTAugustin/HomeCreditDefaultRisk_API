{
 "cells": [
  {
   "source": [
    "## 读入分析数据"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-02T09:54:03.520380Z",
     "start_time": "2020-11-02T09:54:03.516392Z"
    }
   },
   "outputs": [],
   "source": [
    "# numpy and pandas for data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "# sklearn preprocessing for dealing with categorical variables\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, MaxAbsScaler, StandardScaler\n",
    "from sklearn.impute import SimpleImputer as Imputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# File system manangement\n",
    "import os\n",
    "\n",
    "import joblib\n",
    "import requests\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-02T09:54:37.378241Z",
     "start_time": "2020-11-02T09:54:37.370262Z"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['application_test.csv', 'application_train.csv', 'bureau.csv', 'bureau_balance.csv', 'credit_card_balance.csv', 'HomeCredit_columns_description.csv', 'installments_payments.csv', 'POS_CASH_balance.csv', 'previous_application.csv', 'sample_submission.csv']\n"
     ]
    }
   ],
   "source": [
    "# List files available\n",
    "print(os.listdir(\"./input/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-02T09:55:00.329493Z",
     "start_time": "2020-11-02T09:54:56.606423Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training data shape:  (307511, 122)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   SK_ID_CURR  TARGET NAME_CONTRACT_TYPE CODE_GENDER FLAG_OWN_CAR  \\\n",
       "0      100002       1         Cash loans           M            N   \n",
       "1      100003       0         Cash loans           F            N   \n",
       "2      100004       0    Revolving loans           M            Y   \n",
       "3      100006       0         Cash loans           F            N   \n",
       "4      100007       0         Cash loans           M            N   \n",
       "\n",
       "  FLAG_OWN_REALTY  CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY  \\\n",
       "0               Y             0          202500.0    406597.5      24700.5   \n",
       "1               N             0          270000.0   1293502.5      35698.5   \n",
       "2               Y             0           67500.0    135000.0       6750.0   \n",
       "3               Y             0          135000.0    312682.5      29686.5   \n",
       "4               Y             0          121500.0    513000.0      21865.5   \n",
       "\n",
       "   ...  FLAG_DOCUMENT_18 FLAG_DOCUMENT_19 FLAG_DOCUMENT_20 FLAG_DOCUMENT_21  \\\n",
       "0  ...                 0                0                0                0   \n",
       "1  ...                 0                0                0                0   \n",
       "2  ...                 0                0                0                0   \n",
       "3  ...                 0                0                0                0   \n",
       "4  ...                 0                0                0                0   \n",
       "\n",
       "  AMT_REQ_CREDIT_BUREAU_HOUR AMT_REQ_CREDIT_BUREAU_DAY  \\\n",
       "0                        0.0                       0.0   \n",
       "1                        0.0                       0.0   \n",
       "2                        0.0                       0.0   \n",
       "3                        NaN                       NaN   \n",
       "4                        0.0                       0.0   \n",
       "\n",
       "   AMT_REQ_CREDIT_BUREAU_WEEK  AMT_REQ_CREDIT_BUREAU_MON  \\\n",
       "0                         0.0                        0.0   \n",
       "1                         0.0                        0.0   \n",
       "2                         0.0                        0.0   \n",
       "3                         NaN                        NaN   \n",
       "4                         0.0                        0.0   \n",
       "\n",
       "   AMT_REQ_CREDIT_BUREAU_QRT  AMT_REQ_CREDIT_BUREAU_YEAR  \n",
       "0                        0.0                         1.0  \n",
       "1                        0.0                         0.0  \n",
       "2                        0.0                         0.0  \n",
       "3                        NaN                         NaN  \n",
       "4                        0.0                         0.0  \n",
       "\n",
       "[5 rows x 122 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SK_ID_CURR</th>\n      <th>TARGET</th>\n      <th>NAME_CONTRACT_TYPE</th>\n      <th>CODE_GENDER</th>\n      <th>FLAG_OWN_CAR</th>\n      <th>FLAG_OWN_REALTY</th>\n      <th>CNT_CHILDREN</th>\n      <th>AMT_INCOME_TOTAL</th>\n      <th>AMT_CREDIT</th>\n      <th>AMT_ANNUITY</th>\n      <th>...</th>\n      <th>FLAG_DOCUMENT_18</th>\n      <th>FLAG_DOCUMENT_19</th>\n      <th>FLAG_DOCUMENT_20</th>\n      <th>FLAG_DOCUMENT_21</th>\n      <th>AMT_REQ_CREDIT_BUREAU_HOUR</th>\n      <th>AMT_REQ_CREDIT_BUREAU_DAY</th>\n      <th>AMT_REQ_CREDIT_BUREAU_WEEK</th>\n      <th>AMT_REQ_CREDIT_BUREAU_MON</th>\n      <th>AMT_REQ_CREDIT_BUREAU_QRT</th>\n      <th>AMT_REQ_CREDIT_BUREAU_YEAR</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>100002</td>\n      <td>1</td>\n      <td>Cash loans</td>\n      <td>M</td>\n      <td>N</td>\n      <td>Y</td>\n      <td>0</td>\n      <td>202500.0</td>\n      <td>406597.5</td>\n      <td>24700.5</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>100003</td>\n      <td>0</td>\n      <td>Cash loans</td>\n      <td>F</td>\n      <td>N</td>\n      <td>N</td>\n      <td>0</td>\n      <td>270000.0</td>\n      <td>1293502.5</td>\n      <td>35698.5</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>100004</td>\n      <td>0</td>\n      <td>Revolving loans</td>\n      <td>M</td>\n      <td>Y</td>\n      <td>Y</td>\n      <td>0</td>\n      <td>67500.0</td>\n      <td>135000.0</td>\n      <td>6750.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>100006</td>\n      <td>0</td>\n      <td>Cash loans</td>\n      <td>F</td>\n      <td>N</td>\n      <td>Y</td>\n      <td>0</td>\n      <td>135000.0</td>\n      <td>312682.5</td>\n      <td>29686.5</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>100007</td>\n      <td>0</td>\n      <td>Cash loans</td>\n      <td>M</td>\n      <td>N</td>\n      <td>Y</td>\n      <td>0</td>\n      <td>121500.0</td>\n      <td>513000.0</td>\n      <td>21865.5</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 122 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "# Training data\n",
    "app_train = pd.read_csv('./input/application_train.csv')\n",
    "app_test = pd.read_csv('./input/application_test.csv')\n",
    "bureau = pd.read_csv('./input/bureau.csv')\n",
    "bb = pd.read_csv('./input/bureau_balance.csv')\n",
    "prev = pd.read_csv('./input/previous_application.csv')\n",
    "cc = pd.read_csv('./input/credit_card_balance.csv')\n",
    "ins = pd.read_csv('./input/installments_payments.csv')\n",
    "pos = pd.read_csv('./input/POS_CASH_balance.csv')\n",
    "\n",
    "\n",
    "dic={}\n",
    "dic['bur'] = bureau\n",
    "dic['bb'] = bb\n",
    "dic['pre'] = prev\n",
    "dic['cc'] = cc\n",
    "dic['ins'] = ins\n",
    "dic['pos'] = pos\n",
    "\n",
    "print('Training data shape: ', app_train.shape)\n",
    "app_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Features shape:  (307511, 121)\nTesting Features shape:  (48744, 121)\n"
     ]
    }
   ],
   "source": [
    "train_labels = app_train['TARGET']\n",
    "\n",
    "app_train, app_test = app_train.align(app_test, join = 'inner', axis = 1)\n",
    "print('Training Features shape: ', app_train.shape)\n",
    "print('Testing Features shape: ', app_test.shape)"
   ]
  },
  {
   "source": [
    "## 预处理"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding for categorical columns with get_dummies\n",
    "def one_hot_encoder(df, nan_as_category = True):\n",
    "    original_columns = list(df.columns)\n",
    "    categorical_columns = [col for col in df.columns if ((df[col].dtype == 'object') or (df[col].dtype == 'bool'))]\n",
    "    df = pd.get_dummies(df, columns= categorical_columns, dummy_na= nan_as_category)\n",
    "    new_columns = [c for c in df.columns if c not in original_columns]\n",
    "    return df, new_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    " \n",
    "class appTrainTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        return None\n",
    " \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    " \n",
    "    def transform(self, df, y=None):\n",
    "        # DAYS_EMPLOYED_anom\n",
    "        df['DAYS_EMPLOYED_anom'] = (df['DAYS_EMPLOYED'] == 365243)\n",
    "\n",
    "        # Some simple new features (percentages)\n",
    "        docs = [_f for _f in df.columns if 'FLAG_DOC' in _f]\n",
    "        live = [_f for _f in df.columns if ('FLAG_' in _f) & ('FLAG_DOC' not in _f) & ('_FLAG_' not in _f)]\n",
    "        \n",
    "        # NaN values for DAYS_EMPLOYED: 365.243 -> nan\n",
    "        df['DAYS_EMPLOYED'].replace(365243, np.nan, inplace= True)\n",
    "\n",
    "        inc_by_org = df[['AMT_INCOME_TOTAL', 'ORGANIZATION_TYPE']].groupby('ORGANIZATION_TYPE').median()['AMT_INCOME_TOTAL']\n",
    "\n",
    "        df['NEW_CREDIT_TO_ANNUITY_RATIO'] = df['AMT_CREDIT'] / df['AMT_ANNUITY']\n",
    "        df['NEW_CREDIT_TO_GOODS_RATIO'] = df['AMT_CREDIT'] / df['AMT_GOODS_PRICE']\n",
    "        df['NEW_DOC_IND_KURT'] = df[docs].kurtosis(axis=1)\n",
    "        df['NEW_LIVE_IND_SUM'] = df[live].sum(axis=1)\n",
    "        df['NEW_INC_PER_CHLD'] = df['AMT_INCOME_TOTAL'] / (1 + df['CNT_CHILDREN'])\n",
    "        df['NEW_INC_BY_ORG'] = df['ORGANIZATION_TYPE'].map(inc_by_org)\n",
    "        df['NEW_EMPLOY_TO_BIRTH_RATIO'] = df['DAYS_EMPLOYED'] / df['DAYS_BIRTH']\n",
    "        df['NEW_ANNUITY_TO_INCOME_RATIO'] = df['AMT_ANNUITY'] / (1 + df['AMT_INCOME_TOTAL'])\n",
    "        df['NEW_SOURCES_PROD'] = df['EXT_SOURCE_1'] * df['EXT_SOURCE_2'] * df['EXT_SOURCE_3']\n",
    "        df['NEW_EXT_SOURCES_MEAN'] = df[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].mean(axis=1)\n",
    "        df['NEW_SCORES_STD'] = df[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].std(axis=1)\n",
    "        df['NEW_SCORES_STD'] = df['NEW_SCORES_STD'].fillna(df['NEW_SCORES_STD'].mean())\n",
    "        df['NEW_CAR_TO_BIRTH_RATIO'] = df['OWN_CAR_AGE'] / df['DAYS_BIRTH']\n",
    "        df['NEW_CAR_TO_EMPLOY_RATIO'] = df['OWN_CAR_AGE'] / df['DAYS_EMPLOYED']\n",
    "        df['NEW_PHONE_TO_BIRTH_RATIO'] = df['DAYS_LAST_PHONE_CHANGE'] / df['DAYS_BIRTH']\n",
    "        df['NEW_PHONE_TO_BIRTH_RATIO_EMPLOYER'] = df['DAYS_LAST_PHONE_CHANGE'] / df['DAYS_EMPLOYED']\n",
    "        df['NEW_CREDIT_TO_INCOME_RATIO'] = df['AMT_CREDIT'] / df['AMT_INCOME_TOTAL']\n",
    "        \n",
    "        # Categorical features with Binary encode (0 or 1; two categories)\n",
    "        for bin_feature in ['CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY']:\n",
    "            df[bin_feature], uniques = pd.factorize(df[bin_feature])\n",
    "\n",
    "        df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "        return df\n",
    "\n",
    "class dropTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, rate):\n",
    "        self.rate = rate\n",
    "        self.drop = []\n",
    "        return None\n",
    " \n",
    "    def fit(self, X, y=None):\n",
    "        drop = []\n",
    "        for col in X:\n",
    "            if X[col].isna().sum() > self.rate * X.shape[0]:\n",
    "                drop.append(col)\n",
    "        self.drop = drop\n",
    "        return self\n",
    " \n",
    "    def transform(self, X_copy, y=None):\n",
    "        X_copy.drop(self.drop, axis = 1, inplace = True)\n",
    "        X_copy.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "        return X_copy\n",
    "\n",
    "class bureauTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        return None\n",
    " \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    " \n",
    "    def transform(self, bureauinfo, bbinfo, y=None):\n",
    "        # app_train treatment\n",
    "        bb_copy, bb_cat = one_hot_encoder(bbinfo, True)\n",
    "        bureau_copy, bureau_cat = one_hot_encoder(bureauinfo, True)\n",
    "\n",
    "        # bb Treatment\n",
    "        bb_aggregations = {'MONTHS_BALANCE': ['min', 'max', 'size']}\n",
    "        for col in bb_cat:\n",
    "            bb_aggregations[col] = ['mean']\n",
    "        bb_agg = bb_copy.groupby('SK_ID_BUREAU').agg(bb_aggregations)\n",
    "        bb_agg.columns = pd.Index([e[0] + \"_\" + e[1].upper() for e in bb_agg.columns.tolist()])\n",
    "        bureau_copy = bureau_copy.join(bb_agg, how='left', on='SK_ID_BUREAU')\n",
    "        bureau_copy.drop(['SK_ID_BUREAU'], axis=1, inplace= True)\n",
    "\n",
    "        ## bureau Treatment\n",
    "        # Bureau and bureau_balance numeric features\n",
    "        num_aggregations = {\n",
    "            'DAYS_CREDIT': ['min', 'max', 'mean', 'var'],\n",
    "            'DAYS_CREDIT_ENDDATE': ['min', 'max', 'mean'],\n",
    "            'DAYS_CREDIT_UPDATE': ['mean'],\n",
    "            'CREDIT_DAY_OVERDUE': ['max', 'mean'],\n",
    "            'AMT_CREDIT_MAX_OVERDUE': ['mean'],\n",
    "            'AMT_CREDIT_SUM': ['max', 'mean', 'sum'],\n",
    "            'AMT_CREDIT_SUM_DEBT': ['max', 'mean', 'sum'],\n",
    "            'AMT_CREDIT_SUM_OVERDUE': ['mean'],\n",
    "            'AMT_CREDIT_SUM_LIMIT': ['mean', 'sum'],\n",
    "            'AMT_ANNUITY': ['max', 'mean'],\n",
    "            'CNT_CREDIT_PROLONG': ['sum'],\n",
    "            'MONTHS_BALANCE_MIN': ['min'],\n",
    "            'MONTHS_BALANCE_MAX': ['max'],\n",
    "            'MONTHS_BALANCE_SIZE': ['mean', 'sum']\n",
    "        }\n",
    "\n",
    "        # Bureau and bureau_balance categorical features\n",
    "        cat_aggregations = {}\n",
    "        for cat in bureau_cat: \n",
    "            cat_aggregations[cat] = ['mean']\n",
    "        for cat in bb_cat: \n",
    "            cat_aggregations[cat + \"_MEAN\"] = ['mean']\n",
    "\n",
    "        bureau_agg = bureau_copy.groupby('SK_ID_CURR').agg({**num_aggregations, **cat_aggregations})\n",
    "        bureau_agg.columns = pd.Index(['BURO_' + e[0] + \"_\" + e[1].upper() for e in bureau_agg.columns.tolist()])\n",
    "\n",
    "        # Bureau: Active credits - using only numerical aggregations\n",
    "        active = bureau_copy[bureau_copy['CREDIT_ACTIVE_Active'] == 1]\n",
    "        active_agg = active.groupby('SK_ID_CURR').agg(num_aggregations)\n",
    "        active_agg.columns = pd.Index(['ACTIVE_' + e[0] + \"_\" + e[1].upper() for e in active_agg.columns.tolist()])\n",
    "        bureau_agg = bureau_agg.join(active_agg, how='left', on='SK_ID_CURR')\n",
    "\n",
    "\n",
    "        # Bureau: Closed credits - using only numerical aggregations\n",
    "        closed = bureau_copy[bureau_copy['CREDIT_ACTIVE_Closed'] == 1]\n",
    "        closed_agg = closed.groupby('SK_ID_CURR').agg(num_aggregations)\n",
    "        closed_agg.columns = pd.Index(['CLOSED_' + e[0] + \"_\" + e[1].upper() for e in closed_agg.columns.tolist()])\n",
    "        bureau_agg = bureau_agg.join(closed_agg, how='left', on='SK_ID_CURR')\n",
    "\n",
    "        return bureau_agg\n",
    "\n",
    "class previousTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        return None\n",
    " \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    " \n",
    "    def transform(self, previnfo, y=None):\n",
    "\n",
    "        prev, cat_cols = one_hot_encoder(previnfo, nan_as_category= True)\n",
    "        # Days 365.243 values -> nan\n",
    "        prev['DAYS_FIRST_DRAWING'].replace(365243, np.nan, inplace= True)\n",
    "        prev['DAYS_FIRST_DUE'].replace(365243, np.nan, inplace= True)\n",
    "        prev['DAYS_LAST_DUE_1ST_VERSION'].replace(365243, np.nan, inplace= True)\n",
    "        prev['DAYS_LAST_DUE'].replace(365243, np.nan, inplace= True)\n",
    "        prev['DAYS_TERMINATION'].replace(365243, np.nan, inplace= True)\n",
    "\n",
    "        # Add feature: value ask / value received percentage\n",
    "        prev['APP_CREDIT_PERC'] = prev['AMT_APPLICATION'] / prev['AMT_CREDIT']\n",
    "        # Previous applications numeric features\n",
    "        num_aggregations = {\n",
    "            'AMT_ANNUITY': ['min', 'max', 'mean'],\n",
    "            'AMT_APPLICATION': ['min', 'max', 'mean'],\n",
    "            'AMT_CREDIT': ['min', 'max', 'mean'],\n",
    "            'APP_CREDIT_PERC': ['min', 'max', 'mean', 'var'],\n",
    "            'AMT_DOWN_PAYMENT': ['min', 'max', 'mean'],\n",
    "            'AMT_GOODS_PRICE': ['min', 'max', 'mean'],\n",
    "            'HOUR_APPR_PROCESS_START': ['min', 'max', 'mean'],\n",
    "            'RATE_DOWN_PAYMENT': ['min', 'max', 'mean'],\n",
    "            'DAYS_DECISION': ['min', 'max', 'mean'],\n",
    "            'CNT_PAYMENT': ['mean', 'sum'],\n",
    "        }\n",
    "        # Previous applications categorical features\n",
    "        cat_aggregations = {}\n",
    "        for cat in cat_cols:\n",
    "            cat_aggregations[cat] = ['mean']\n",
    "        \n",
    "        prev_agg = prev.groupby('SK_ID_CURR').agg({**num_aggregations, **cat_aggregations})\n",
    "        prev_agg.columns = pd.Index(['PREV_' + e[0] + \"_\" + e[1].upper() for e in prev_agg.columns.tolist()])\n",
    "        # Previous Applications: Approved Applications - only numerical features\n",
    "        approved = prev[prev['NAME_CONTRACT_STATUS_Approved'] == 1]\n",
    "        approved_agg = approved.groupby('SK_ID_CURR').agg(num_aggregations)\n",
    "        approved_agg.columns = pd.Index(['APPROVED_' + e[0] + \"_\" + e[1].upper() for e in approved_agg.columns.tolist()])\n",
    "        prev_agg = prev_agg.join(approved_agg, how='left', on='SK_ID_CURR')\n",
    "        # Previous Applications: Refused Applications - only numerical features\n",
    "        refused = prev[prev['NAME_CONTRACT_STATUS_Refused'] == 1]\n",
    "        refused_agg = refused.groupby('SK_ID_CURR').agg(num_aggregations)\n",
    "        refused_agg.columns = pd.Index(['REFUSED_' + e[0] + \"_\" + e[1].upper() for e in refused_agg.columns.tolist()])\n",
    "        prev_agg = prev_agg.join(refused_agg, how='left', on='SK_ID_CURR')\n",
    "\n",
    "        return prev_agg\n",
    "\n",
    "class posTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        return None\n",
    " \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    " \n",
    "    def transform(self, posinfo, y=None):\n",
    "\n",
    "        pos, cat_cols = one_hot_encoder(posinfo, True)\n",
    "        # Features\n",
    "        aggregations = {\n",
    "            'MONTHS_BALANCE': ['max', 'mean', 'size'],\n",
    "            'SK_DPD': ['max', 'mean'],\n",
    "            'SK_DPD_DEF': ['max', 'mean']\n",
    "        }\n",
    "        for cat in cat_cols:\n",
    "            aggregations[cat] = ['mean']\n",
    "        \n",
    "        pos_agg = pos.groupby('SK_ID_CURR').agg(aggregations)\n",
    "        pos_agg.columns = pd.Index(['POS_' + e[0] + \"_\" + e[1].upper() for e in pos_agg.columns.tolist()])\n",
    "        # Count pos cash accounts\n",
    "        pos_agg['POS_COUNT'] = pos.groupby('SK_ID_CURR').size()\n",
    "\n",
    "        return pos_agg\n",
    "    \n",
    "class installmentsTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        return None\n",
    " \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    " \n",
    "    def transform(self, insinfo, y=None):\n",
    "        ins, cat_cols = one_hot_encoder(insinfo, True)\n",
    "\n",
    "        # Percentage and difference paid in each installment (amount paid and installment value)\n",
    "        ins['PAYMENT_PERC'] = ins['AMT_PAYMENT'] / ins['AMT_INSTALMENT']\n",
    "        ins['PAYMENT_DIFF'] = ins['AMT_INSTALMENT'] - ins['AMT_PAYMENT']\n",
    "        # Days past due and days before due (no negative values)\n",
    "        ins['DPD'] = ins['DAYS_ENTRY_PAYMENT'] - ins['DAYS_INSTALMENT']\n",
    "        ins['DBD'] = ins['DAYS_INSTALMENT'] - ins['DAYS_ENTRY_PAYMENT']\n",
    "        ins['DPD'] = ins['DPD'].apply(lambda x: x if x > 0 else 0)\n",
    "        ins['DBD'] = ins['DBD'].apply(lambda x: x if x > 0 else 0)\n",
    "        # Features: Perform aggregations\n",
    "        aggregations = {\n",
    "            'NUM_INSTALMENT_VERSION': ['nunique'],\n",
    "            'DPD': ['max', 'mean', 'sum'],\n",
    "            'DBD': ['max', 'mean', 'sum'],\n",
    "            'PAYMENT_PERC': ['max', 'mean', 'sum', 'var'],\n",
    "            'PAYMENT_DIFF': ['max', 'mean', 'sum', 'var'],\n",
    "            'AMT_INSTALMENT': ['max', 'mean', 'sum'],\n",
    "            'AMT_PAYMENT': ['min', 'max', 'mean', 'sum'],\n",
    "            'DAYS_ENTRY_PAYMENT': ['max', 'mean', 'sum']\n",
    "        }\n",
    "        for cat in cat_cols:\n",
    "            aggregations[cat] = ['mean']\n",
    "        ins_agg = ins.groupby('SK_ID_CURR').agg(aggregations)\n",
    "        ins_agg.columns = pd.Index(['INSTAL_' + e[0] + \"_\" + e[1].upper() for e in ins_agg.columns.tolist()])\n",
    "        # Count installments accounts\n",
    "        ins_agg['INSTAL_COUNT'] = ins.groupby('SK_ID_CURR').size()\n",
    "        return ins_agg\n",
    "\n",
    "class ccTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        return None\n",
    " \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    " \n",
    "    def transform(self, ccinfo, y=None):\n",
    "        cc, cat_cols = one_hot_encoder(ccinfo, True)\n",
    "        # General aggregations\n",
    "        cc.drop(['SK_ID_PREV'], axis= 1, inplace = True)\n",
    "        cc_agg = cc.groupby('SK_ID_CURR').agg(['min', 'max', 'mean', 'sum', 'var'])\n",
    "        cc_agg.columns = pd.Index(['CC_' + e[0] + \"_\" + e[1].upper() for e in cc_agg.columns.tolist()])\n",
    "        # Count credit card lines\n",
    "        cc_agg['CC_COUNT'] = cc.groupby('SK_ID_CURR').size()\n",
    "        return cc_agg\n",
    "\n",
    "class dropImportanceTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, di):\n",
    "        self.di = di\n",
    "        return None\n",
    " \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    " \n",
    "    def transform(self, X, y=None):\n",
    "        return np.delete(X, self.di, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bur = bureauTransformer().transform(dic['bur'], dic['bb'])\n",
    "pre = previousTransformer().transform(dic['pre'])\n",
    "pos = posTransformer().transform(dic['pos'])\n",
    "cc = ccTransformer().transform(dic['cc'])\n",
    "ins = installmentsTransformer().transform(dic['ins'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join(X):\n",
    "    X = X.join(bur, how='left', on='SK_ID_CURR')\n",
    "    X = X.join(pre, how='left', on='SK_ID_CURR')\n",
    "    X = X.join(pos, how='left', on='SK_ID_CURR')\n",
    "    X = X.join(cc, how='left', on='SK_ID_CURR')\n",
    "    X = X.join(ins, how='left', on='SK_ID_CURR')\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of categorical feature: 14\nNumber of numerical feature: 498\n"
     ]
    }
   ],
   "source": [
    "X = app_train.copy()\n",
    "X = join(X)\n",
    "X = appTrainTransformer().transform(X)\n",
    "X = dropTransformer(0.7).fit_transform(X)\n",
    "\n",
    "\n",
    "numeric_columns = []\n",
    "category_columns = []\n",
    "\n",
    "for col in X:\n",
    "    \n",
    "    if X[col].dtype == ('object') or X[col].dtype == ('bool'):\n",
    "        category_columns.append(col)\n",
    "    else:\n",
    "        numeric_columns.append(col)\n",
    "\n",
    "print(\"Number of categorical feature:\", len(category_columns))\n",
    "print(\"Number of numerical feature:\", len(numeric_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('impute_nan', Imputer(missing_values=np.nan,strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "category_transformer = Pipeline(steps=[\n",
    "    ('impute', Imputer(strategy='constant', fill_value='missing')),\n",
    "    ('ohe', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocesser = ColumnTransformer(transformers=[\n",
    "    ('numeric', numeric_transformer, numeric_columns),\n",
    "    ('category', category_transformer, category_columns)\n",
    "]) \n",
    "\n",
    "pipeline_av = Pipeline(steps=[\n",
    "    ('app', appTrainTransformer()),\n",
    "    ('drop', dropTransformer(0.7)),\n",
    "    ('preprocesser', preprocesser)\n",
    "])"
   ]
  },
  {
   "source": [
    "## Feature Importance"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_av_train = app_train.copy()\n",
    "app_av_train = join(app_av_train)\n",
    "\n",
    "app_av_test = app_test.copy()\n",
    "app_av_test = join(app_av_test)\n",
    "\n",
    "app_pre_train = pipeline_av.fit_transform(app_av_train)\n",
    "df_train = pd.DataFrame(app_pre_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def getDeleteFeature(k, X, y):\n",
    "    result = np.arange(0, X.shape[1])\n",
    "    kf = KFold(n_splits=k)\n",
    "    for train_index, test_index in kf.split(X):\n",
    "\n",
    "        X_train, X_test = X.iloc[train_index,:], X.iloc[test_index,:]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        gbm = lgb.LGBMClassifier(\n",
    "            nthread=4,\n",
    "            n_estimators=10000,\n",
    "            learning_rate=0.02,\n",
    "            num_leaves=34,\n",
    "            colsample_bytree=0.9497036,\n",
    "            subsample=0.8715623,\n",
    "            max_depth=8,\n",
    "            reg_alpha=0.041545473,\n",
    "            reg_lambda=0.0735294,\n",
    "            min_split_gain=0.0222415,\n",
    "            min_child_weight=39.3259775,\n",
    "            silent=-1,\n",
    "            verbose=-1, )\n",
    "        gbm.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_test, y_test)], eval_metric= 'auc', verbose= 50, early_stopping_rounds= 200)\n",
    "        drop_importance = np.where(gbm.feature_importances_ <= 1)[0]\n",
    "        result = np.intersect1d(drop_importance, result)\n",
    "    return result     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1's auc: 0.787032\tvalid_1's binary_logloss: 0.23536\n",
      "[1100]\ttraining's auc: 0.865693\ttraining's binary_logloss: 0.207132\tvalid_1's auc: 0.787148\tvalid_1's binary_logloss: 0.235319\n",
      "[1150]\ttraining's auc: 0.868202\ttraining's binary_logloss: 0.206045\tvalid_1's auc: 0.787175\tvalid_1's binary_logloss: 0.235311\n",
      "[1200]\ttraining's auc: 0.870808\ttraining's binary_logloss: 0.204886\tvalid_1's auc: 0.787257\tvalid_1's binary_logloss: 0.235287\n",
      "[1250]\ttraining's auc: 0.873154\ttraining's binary_logloss: 0.203854\tvalid_1's auc: 0.787287\tvalid_1's binary_logloss: 0.235287\n",
      "[1300]\ttraining's auc: 0.875535\ttraining's binary_logloss: 0.202761\tvalid_1's auc: 0.787458\tvalid_1's binary_logloss: 0.235239\n",
      "[1350]\ttraining's auc: 0.877632\ttraining's binary_logloss: 0.201795\tvalid_1's auc: 0.787447\tvalid_1's binary_logloss: 0.235238\n",
      "[1400]\ttraining's auc: 0.879905\ttraining's binary_logloss: 0.20075\tvalid_1's auc: 0.787489\tvalid_1's binary_logloss: 0.235222\n",
      "[1450]\ttraining's auc: 0.882069\ttraining's binary_logloss: 0.199747\tvalid_1's auc: 0.787463\tvalid_1's binary_logloss: 0.235249\n",
      "[1500]\ttraining's auc: 0.884266\ttraining's binary_logloss: 0.198715\tvalid_1's auc: 0.787496\tvalid_1's binary_logloss: 0.235241\n",
      "[1550]\ttraining's auc: 0.886368\ttraining's binary_logloss: 0.19775\tvalid_1's auc: 0.787533\tvalid_1's binary_logloss: 0.235248\n",
      "[1600]\ttraining's auc: 0.888525\ttraining's binary_logloss: 0.196728\tvalid_1's auc: 0.787442\tvalid_1's binary_logloss: 0.235292\n",
      "Early stopping, best iteration is:\n",
      "[1401]\ttraining's auc: 0.879948\ttraining's binary_logloss: 0.200728\tvalid_1's auc: 0.787493\tvalid_1's binary_logloss: 0.23522\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\ttraining's auc: 0.756039\ttraining's binary_logloss: 0.251744\tvalid_1's auc: 0.744611\tvalid_1's binary_logloss: 0.259436\n",
      "[100]\ttraining's auc: 0.77257\ttraining's binary_logloss: 0.243318\tvalid_1's auc: 0.757115\tvalid_1's binary_logloss: 0.252614\n",
      "[150]\ttraining's auc: 0.785312\ttraining's binary_logloss: 0.238171\tvalid_1's auc: 0.766915\tvalid_1's binary_logloss: 0.248864\n",
      "[200]\ttraining's auc: 0.794629\ttraining's binary_logloss: 0.234461\tvalid_1's auc: 0.772641\tvalid_1's binary_logloss: 0.246669\n",
      "[250]\ttraining's auc: 0.802214\ttraining's binary_logloss: 0.231483\tvalid_1's auc: 0.776887\tvalid_1's binary_logloss: 0.24508\n",
      "[300]\ttraining's auc: 0.808447\ttraining's binary_logloss: 0.228996\tvalid_1's auc: 0.779987\tvalid_1's binary_logloss: 0.24395\n",
      "[350]\ttraining's auc: 0.813889\ttraining's binary_logloss: 0.226848\tvalid_1's auc: 0.782229\tvalid_1's binary_logloss: 0.243124\n",
      "[400]\ttraining's auc: 0.818745\ttraining's binary_logloss: 0.224937\tvalid_1's auc: 0.78401\tvalid_1's binary_logloss: 0.242462\n",
      "[450]\ttraining's auc: 0.82337\ttraining's binary_logloss: 0.223141\tvalid_1's auc: 0.785435\tvalid_1's binary_logloss: 0.24195\n",
      "[500]\ttraining's auc: 0.827482\ttraining's binary_logloss: 0.221543\tvalid_1's auc: 0.786572\tvalid_1's binary_logloss: 0.241567\n",
      "[550]\ttraining's auc: 0.83133\ttraining's binary_logloss: 0.220032\tvalid_1's auc: 0.787509\tvalid_1's binary_logloss: 0.241249\n",
      "[600]\ttraining's auc: 0.835037\ttraining's binary_logloss: 0.218553\tvalid_1's auc: 0.788213\tvalid_1's binary_logloss: 0.241004\n",
      "[650]\ttraining's auc: 0.838466\ttraining's binary_logloss: 0.2172\tvalid_1's auc: 0.788736\tvalid_1's binary_logloss: 0.240824\n",
      "[700]\ttraining's auc: 0.841732\ttraining's binary_logloss: 0.215867\tvalid_1's auc: 0.7892\tvalid_1's binary_logloss: 0.240668\n",
      "[750]\ttraining's auc: 0.844867\ttraining's binary_logloss: 0.21459\tvalid_1's auc: 0.789491\tvalid_1's binary_logloss: 0.240563\n",
      "[800]\ttraining's auc: 0.847955\ttraining's binary_logloss: 0.213335\tvalid_1's auc: 0.78978\tvalid_1's binary_logloss: 0.240469\n",
      "[850]\ttraining's auc: 0.850923\ttraining's binary_logloss: 0.212127\tvalid_1's auc: 0.790159\tvalid_1's binary_logloss: 0.24037\n",
      "[900]\ttraining's auc: 0.85388\ttraining's binary_logloss: 0.210949\tvalid_1's auc: 0.790428\tvalid_1's binary_logloss: 0.240285\n",
      "[950]\ttraining's auc: 0.856761\ttraining's binary_logloss: 0.209785\tvalid_1's auc: 0.790652\tvalid_1's binary_logloss: 0.240196\n",
      "[1000]\ttraining's auc: 0.859216\ttraining's binary_logloss: 0.208758\tvalid_1's auc: 0.790791\tvalid_1's binary_logloss: 0.240152\n",
      "[1050]\ttraining's auc: 0.861744\ttraining's binary_logloss: 0.20765\tvalid_1's auc: 0.791035\tvalid_1's binary_logloss: 0.240075\n",
      "[1100]\ttraining's auc: 0.864286\ttraining's binary_logloss: 0.206551\tvalid_1's auc: 0.791216\tvalid_1's binary_logloss: 0.24003\n",
      "[1150]\ttraining's auc: 0.866707\ttraining's binary_logloss: 0.205512\tvalid_1's auc: 0.791357\tvalid_1's binary_logloss: 0.239987\n",
      "[1200]\ttraining's auc: 0.86901\ttraining's binary_logloss: 0.204513\tvalid_1's auc: 0.791405\tvalid_1's binary_logloss: 0.239971\n",
      "[1250]\ttraining's auc: 0.871362\ttraining's binary_logloss: 0.203482\tvalid_1's auc: 0.791494\tvalid_1's binary_logloss: 0.23993\n",
      "[1300]\ttraining's auc: 0.873739\ttraining's binary_logloss: 0.202397\tvalid_1's auc: 0.791521\tvalid_1's binary_logloss: 0.23993\n",
      "[1350]\ttraining's auc: 0.876093\ttraining's binary_logloss: 0.201315\tvalid_1's auc: 0.791584\tvalid_1's binary_logloss: 0.23991\n",
      "[1400]\ttraining's auc: 0.878431\ttraining's binary_logloss: 0.200238\tvalid_1's auc: 0.791577\tvalid_1's binary_logloss: 0.239917\n",
      "[1450]\ttraining's auc: 0.880621\ttraining's binary_logloss: 0.199213\tvalid_1's auc: 0.791585\tvalid_1's binary_logloss: 0.239917\n",
      "[1500]\ttraining's auc: 0.882816\ttraining's binary_logloss: 0.198194\tvalid_1's auc: 0.79172\tvalid_1's binary_logloss: 0.239894\n",
      "[1550]\ttraining's auc: 0.884908\ttraining's binary_logloss: 0.197207\tvalid_1's auc: 0.791737\tvalid_1's binary_logloss: 0.239893\n",
      "[1600]\ttraining's auc: 0.886875\ttraining's binary_logloss: 0.196244\tvalid_1's auc: 0.791808\tvalid_1's binary_logloss: 0.239887\n",
      "[1650]\ttraining's auc: 0.888901\ttraining's binary_logloss: 0.195268\tvalid_1's auc: 0.791805\tvalid_1's binary_logloss: 0.2399\n",
      "[1700]\ttraining's auc: 0.89109\ttraining's binary_logloss: 0.194233\tvalid_1's auc: 0.791942\tvalid_1's binary_logloss: 0.23987\n",
      "[1750]\ttraining's auc: 0.893006\ttraining's binary_logloss: 0.193284\tvalid_1's auc: 0.791942\tvalid_1's binary_logloss: 0.239885\n",
      "[1800]\ttraining's auc: 0.894986\ttraining's binary_logloss: 0.192334\tvalid_1's auc: 0.791925\tvalid_1's binary_logloss: 0.239898\n",
      "[1850]\ttraining's auc: 0.896833\ttraining's binary_logloss: 0.19142\tvalid_1's auc: 0.79192\tvalid_1's binary_logloss: 0.239928\n",
      "[1900]\ttraining's auc: 0.898808\ttraining's binary_logloss: 0.19043\tvalid_1's auc: 0.7918\tvalid_1's binary_logloss: 0.239969\n",
      "Early stopping, best iteration is:\n",
      "[1710]\ttraining's auc: 0.891506\ttraining's binary_logloss: 0.194033\tvalid_1's auc: 0.791963\tvalid_1's binary_logloss: 0.239863\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\ttraining's auc: 0.758498\ttraining's binary_logloss: 0.25215\tvalid_1's auc: 0.73729\tvalid_1's binary_logloss: 0.257027\n",
      "[100]\ttraining's auc: 0.774096\ttraining's binary_logloss: 0.243623\tvalid_1's auc: 0.748886\tvalid_1's binary_logloss: 0.250741\n",
      "[150]\ttraining's auc: 0.786906\ttraining's binary_logloss: 0.238449\tvalid_1's auc: 0.758035\tvalid_1's binary_logloss: 0.247451\n",
      "[200]\ttraining's auc: 0.796449\ttraining's binary_logloss: 0.234651\tvalid_1's auc: 0.764586\tvalid_1's binary_logloss: 0.245293\n",
      "[250]\ttraining's auc: 0.803736\ttraining's binary_logloss: 0.231701\tvalid_1's auc: 0.768234\tvalid_1's binary_logloss: 0.24402\n",
      "[300]\ttraining's auc: 0.80985\ttraining's binary_logloss: 0.22923\tvalid_1's auc: 0.771035\tvalid_1's binary_logloss: 0.243084\n",
      "[350]\ttraining's auc: 0.815272\ttraining's binary_logloss: 0.227057\tvalid_1's auc: 0.773308\tvalid_1's binary_logloss: 0.242347\n",
      "[400]\ttraining's auc: 0.819869\ttraining's binary_logloss: 0.225169\tvalid_1's auc: 0.775241\tvalid_1's binary_logloss: 0.241736\n",
      "[450]\ttraining's auc: 0.824321\ttraining's binary_logloss: 0.223403\tvalid_1's auc: 0.776737\tvalid_1's binary_logloss: 0.24127\n",
      "[500]\ttraining's auc: 0.828336\ttraining's binary_logloss: 0.221806\tvalid_1's auc: 0.777815\tvalid_1's binary_logloss: 0.240929\n",
      "[550]\ttraining's auc: 0.832069\ttraining's binary_logloss: 0.220339\tvalid_1's auc: 0.778542\tvalid_1's binary_logloss: 0.240677\n",
      "[600]\ttraining's auc: 0.835587\ttraining's binary_logloss: 0.218926\tvalid_1's auc: 0.779413\tvalid_1's binary_logloss: 0.240403\n",
      "[650]\ttraining's auc: 0.838942\ttraining's binary_logloss: 0.21757\tvalid_1's auc: 0.780008\tvalid_1's binary_logloss: 0.24019\n",
      "[700]\ttraining's auc: 0.842268\ttraining's binary_logloss: 0.216247\tvalid_1's auc: 0.780403\tvalid_1's binary_logloss: 0.240047\n",
      "[750]\ttraining's auc: 0.845597\ttraining's binary_logloss: 0.214925\tvalid_1's auc: 0.780816\tvalid_1's binary_logloss: 0.239911\n",
      "[800]\ttraining's auc: 0.848709\ttraining's binary_logloss: 0.213644\tvalid_1's auc: 0.781174\tvalid_1's binary_logloss: 0.239785\n",
      "[850]\ttraining's auc: 0.851788\ttraining's binary_logloss: 0.212361\tvalid_1's auc: 0.781459\tvalid_1's binary_logloss: 0.239688\n",
      "[900]\ttraining's auc: 0.854836\ttraining's binary_logloss: 0.21113\tvalid_1's auc: 0.781742\tvalid_1's binary_logloss: 0.239597\n",
      "[950]\ttraining's auc: 0.857556\ttraining's binary_logloss: 0.209945\tvalid_1's auc: 0.781985\tvalid_1's binary_logloss: 0.239509\n",
      "[1000]\ttraining's auc: 0.860351\ttraining's binary_logloss: 0.208751\tvalid_1's auc: 0.782273\tvalid_1's binary_logloss: 0.239414\n",
      "[1050]\ttraining's auc: 0.863009\ttraining's binary_logloss: 0.207605\tvalid_1's auc: 0.782482\tvalid_1's binary_logloss: 0.239344\n",
      "[1100]\ttraining's auc: 0.865647\ttraining's binary_logloss: 0.206451\tvalid_1's auc: 0.782542\tvalid_1's binary_logloss: 0.23932\n",
      "[1150]\ttraining's auc: 0.868108\ttraining's binary_logloss: 0.205361\tvalid_1's auc: 0.782594\tvalid_1's binary_logloss: 0.239278\n",
      "[1200]\ttraining's auc: 0.870529\ttraining's binary_logloss: 0.204284\tvalid_1's auc: 0.782708\tvalid_1's binary_logloss: 0.239245\n",
      "[1250]\ttraining's auc: 0.872941\ttraining's binary_logloss: 0.203211\tvalid_1's auc: 0.782792\tvalid_1's binary_logloss: 0.239228\n",
      "[1300]\ttraining's auc: 0.875227\ttraining's binary_logloss: 0.20216\tvalid_1's auc: 0.782948\tvalid_1's binary_logloss: 0.239181\n",
      "[1350]\ttraining's auc: 0.877567\ttraining's binary_logloss: 0.20109\tvalid_1's auc: 0.783003\tvalid_1's binary_logloss: 0.239182\n",
      "[1400]\ttraining's auc: 0.879853\ttraining's binary_logloss: 0.200057\tvalid_1's auc: 0.782892\tvalid_1's binary_logloss: 0.239219\n",
      "[1450]\ttraining's auc: 0.882027\ttraining's binary_logloss: 0.199042\tvalid_1's auc: 0.782959\tvalid_1's binary_logloss: 0.239224\n",
      "[1500]\ttraining's auc: 0.884253\ttraining's binary_logloss: 0.197993\tvalid_1's auc: 0.78293\tvalid_1's binary_logloss: 0.23924\n",
      "Early stopping, best iteration is:\n",
      "[1323]\ttraining's auc: 0.876347\ttraining's binary_logloss: 0.201643\tvalid_1's auc: 0.783033\tvalid_1's binary_logloss: 0.239161\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\ttraining's auc: 0.756153\ttraining's binary_logloss: 0.253138\tvalid_1's auc: 0.748076\tvalid_1's binary_logloss: 0.253783\n",
      "[100]\ttraining's auc: 0.772295\ttraining's binary_logloss: 0.244632\tvalid_1's auc: 0.759439\tvalid_1's binary_logloss: 0.246957\n",
      "[150]\ttraining's auc: 0.785259\ttraining's binary_logloss: 0.239424\tvalid_1's auc: 0.767946\tvalid_1's binary_logloss: 0.243447\n",
      "[200]\ttraining's auc: 0.794758\ttraining's binary_logloss: 0.235667\tvalid_1's auc: 0.77359\tvalid_1's binary_logloss: 0.241233\n",
      "[250]\ttraining's auc: 0.802176\ttraining's binary_logloss: 0.232668\tvalid_1's auc: 0.777174\tvalid_1's binary_logloss: 0.239782\n",
      "[300]\ttraining's auc: 0.808461\ttraining's binary_logloss: 0.23016\tvalid_1's auc: 0.779629\tvalid_1's binary_logloss: 0.238788\n",
      "[350]\ttraining's auc: 0.813756\ttraining's binary_logloss: 0.228009\tvalid_1's auc: 0.781384\tvalid_1's binary_logloss: 0.238076\n",
      "[400]\ttraining's auc: 0.818461\ttraining's binary_logloss: 0.226135\tvalid_1's auc: 0.782872\tvalid_1's binary_logloss: 0.23752\n",
      "[450]\ttraining's auc: 0.822851\ttraining's binary_logloss: 0.224365\tvalid_1's auc: 0.784194\tvalid_1's binary_logloss: 0.237046\n",
      "[500]\ttraining's auc: 0.826984\ttraining's binary_logloss: 0.222757\tvalid_1's auc: 0.785137\tvalid_1's binary_logloss: 0.236724\n",
      "[550]\ttraining's auc: 0.831027\ttraining's binary_logloss: 0.221181\tvalid_1's auc: 0.785808\tvalid_1's binary_logloss: 0.236467\n",
      "[600]\ttraining's auc: 0.834721\ttraining's binary_logloss: 0.219692\tvalid_1's auc: 0.786653\tvalid_1's binary_logloss: 0.236182\n",
      "[650]\ttraining's auc: 0.83807\ttraining's binary_logloss: 0.218345\tvalid_1's auc: 0.78719\tvalid_1's binary_logloss: 0.235999\n",
      "[700]\ttraining's auc: 0.841235\ttraining's binary_logloss: 0.217087\tvalid_1's auc: 0.787635\tvalid_1's binary_logloss: 0.235852\n",
      "[750]\ttraining's auc: 0.844408\ttraining's binary_logloss: 0.21581\tvalid_1's auc: 0.788146\tvalid_1's binary_logloss: 0.2357\n",
      "[800]\ttraining's auc: 0.847626\ttraining's binary_logloss: 0.214559\tvalid_1's auc: 0.788554\tvalid_1's binary_logloss: 0.235558\n",
      "[850]\ttraining's auc: 0.850566\ttraining's binary_logloss: 0.213331\tvalid_1's auc: 0.78876\tvalid_1's binary_logloss: 0.235492\n",
      "[900]\ttraining's auc: 0.853414\ttraining's binary_logloss: 0.212166\tvalid_1's auc: 0.789007\tvalid_1's binary_logloss: 0.23541\n",
      "[950]\ttraining's auc: 0.856267\ttraining's binary_logloss: 0.210958\tvalid_1's auc: 0.789034\tvalid_1's binary_logloss: 0.23539\n",
      "[1000]\ttraining's auc: 0.859084\ttraining's binary_logloss: 0.20977\tvalid_1's auc: 0.789169\tvalid_1's binary_logloss: 0.235342\n",
      "[1050]\ttraining's auc: 0.861521\ttraining's binary_logloss: 0.208708\tvalid_1's auc: 0.789257\tvalid_1's binary_logloss: 0.2353\n",
      "[1100]\ttraining's auc: 0.864147\ttraining's binary_logloss: 0.207578\tvalid_1's auc: 0.789335\tvalid_1's binary_logloss: 0.235268\n",
      "[1150]\ttraining's auc: 0.866631\ttraining's binary_logloss: 0.206487\tvalid_1's auc: 0.789443\tvalid_1's binary_logloss: 0.23524\n",
      "[1200]\ttraining's auc: 0.868964\ttraining's binary_logloss: 0.205433\tvalid_1's auc: 0.789493\tvalid_1's binary_logloss: 0.235234\n",
      "[1250]\ttraining's auc: 0.871137\ttraining's binary_logloss: 0.204451\tvalid_1's auc: 0.789652\tvalid_1's binary_logloss: 0.23519\n",
      "[1300]\ttraining's auc: 0.873346\ttraining's binary_logloss: 0.203421\tvalid_1's auc: 0.789709\tvalid_1's binary_logloss: 0.235175\n",
      "[1350]\ttraining's auc: 0.875584\ttraining's binary_logloss: 0.202372\tvalid_1's auc: 0.789829\tvalid_1's binary_logloss: 0.235131\n",
      "[1400]\ttraining's auc: 0.877689\ttraining's binary_logloss: 0.20136\tvalid_1's auc: 0.789884\tvalid_1's binary_logloss: 0.235125\n",
      "[1450]\ttraining's auc: 0.879842\ttraining's binary_logloss: 0.200398\tvalid_1's auc: 0.789932\tvalid_1's binary_logloss: 0.235126\n",
      "[1500]\ttraining's auc: 0.882003\ttraining's binary_logloss: 0.199407\tvalid_1's auc: 0.789914\tvalid_1's binary_logloss: 0.235137\n",
      "[1550]\ttraining's auc: 0.884265\ttraining's binary_logloss: 0.198371\tvalid_1's auc: 0.789932\tvalid_1's binary_logloss: 0.235138\n",
      "Early stopping, best iteration is:\n",
      "[1395]\ttraining's auc: 0.877474\ttraining's binary_logloss: 0.201465\tvalid_1's auc: 0.789905\tvalid_1's binary_logloss: 0.235115\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\ttraining's auc: 0.755655\ttraining's binary_logloss: 0.253672\tvalid_1's auc: 0.75106\tvalid_1's binary_logloss: 0.251883\n",
      "[100]\ttraining's auc: 0.771484\ttraining's binary_logloss: 0.245233\tvalid_1's auc: 0.761876\tvalid_1's binary_logloss: 0.24499\n",
      "[150]\ttraining's auc: 0.78464\ttraining's binary_logloss: 0.239998\tvalid_1's auc: 0.770737\tvalid_1's binary_logloss: 0.241333\n",
      "[200]\ttraining's auc: 0.794137\ttraining's binary_logloss: 0.236244\tvalid_1's auc: 0.776099\tvalid_1's binary_logloss: 0.239179\n",
      "[250]\ttraining's auc: 0.801697\ttraining's binary_logloss: 0.233237\tvalid_1's auc: 0.779923\tvalid_1's binary_logloss: 0.23767\n",
      "[300]\ttraining's auc: 0.807957\ttraining's binary_logloss: 0.230736\tvalid_1's auc: 0.782269\tvalid_1's binary_logloss: 0.236691\n",
      "[350]\ttraining's auc: 0.813268\ttraining's binary_logloss: 0.228613\tvalid_1's auc: 0.784214\tvalid_1's binary_logloss: 0.235954\n",
      "[400]\ttraining's auc: 0.818245\ttraining's binary_logloss: 0.226665\tvalid_1's auc: 0.78565\tvalid_1's binary_logloss: 0.235428\n",
      "[450]\ttraining's auc: 0.822758\ttraining's binary_logloss: 0.224889\tvalid_1's auc: 0.786739\tvalid_1's binary_logloss: 0.235014\n",
      "[500]\ttraining's auc: 0.826852\ttraining's binary_logloss: 0.223265\tvalid_1's auc: 0.787756\tvalid_1's binary_logloss: 0.234648\n",
      "[550]\ttraining's auc: 0.830761\ttraining's binary_logloss: 0.221722\tvalid_1's auc: 0.788487\tvalid_1's binary_logloss: 0.234395\n",
      "[600]\ttraining's auc: 0.834407\ttraining's binary_logloss: 0.220273\tvalid_1's auc: 0.789161\tvalid_1's binary_logloss: 0.234158\n",
      "[650]\ttraining's auc: 0.837765\ttraining's binary_logloss: 0.218963\tvalid_1's auc: 0.789504\tvalid_1's binary_logloss: 0.234035\n",
      "[700]\ttraining's auc: 0.841092\ttraining's binary_logloss: 0.217654\tvalid_1's auc: 0.789766\tvalid_1's binary_logloss: 0.23394\n",
      "[750]\ttraining's auc: 0.844404\ttraining's binary_logloss: 0.216326\tvalid_1's auc: 0.790172\tvalid_1's binary_logloss: 0.233797\n",
      "[800]\ttraining's auc: 0.847421\ttraining's binary_logloss: 0.215117\tvalid_1's auc: 0.790608\tvalid_1's binary_logloss: 0.233665\n",
      "[850]\ttraining's auc: 0.850238\ttraining's binary_logloss: 0.213989\tvalid_1's auc: 0.790787\tvalid_1's binary_logloss: 0.23359\n",
      "[900]\ttraining's auc: 0.853162\ttraining's binary_logloss: 0.212782\tvalid_1's auc: 0.791014\tvalid_1's binary_logloss: 0.233507\n",
      "[950]\ttraining's auc: 0.855953\ttraining's binary_logloss: 0.211629\tvalid_1's auc: 0.791288\tvalid_1's binary_logloss: 0.233414\n",
      "[1000]\ttraining's auc: 0.858724\ttraining's binary_logloss: 0.210482\tvalid_1's auc: 0.791371\tvalid_1's binary_logloss: 0.233391\n",
      "[1050]\ttraining's auc: 0.861327\ttraining's binary_logloss: 0.209373\tvalid_1's auc: 0.791536\tvalid_1's binary_logloss: 0.233336\n",
      "[1100]\ttraining's auc: 0.863855\ttraining's binary_logloss: 0.208263\tvalid_1's auc: 0.791634\tvalid_1's binary_logloss: 0.233303\n",
      "[1150]\ttraining's auc: 0.866407\ttraining's binary_logloss: 0.207166\tvalid_1's auc: 0.791703\tvalid_1's binary_logloss: 0.233271\n",
      "[1200]\ttraining's auc: 0.868859\ttraining's binary_logloss: 0.20609\tvalid_1's auc: 0.79177\tvalid_1's binary_logloss: 0.233253\n",
      "[1250]\ttraining's auc: 0.871092\ttraining's binary_logloss: 0.205114\tvalid_1's auc: 0.791796\tvalid_1's binary_logloss: 0.233244\n",
      "[1300]\ttraining's auc: 0.873531\ttraining's binary_logloss: 0.20404\tvalid_1's auc: 0.791874\tvalid_1's binary_logloss: 0.233208\n",
      "[1350]\ttraining's auc: 0.875782\ttraining's binary_logloss: 0.203044\tvalid_1's auc: 0.791905\tvalid_1's binary_logloss: 0.233191\n",
      "[1400]\ttraining's auc: 0.878109\ttraining's binary_logloss: 0.201989\tvalid_1's auc: 0.791929\tvalid_1's binary_logloss: 0.233186\n",
      "[1450]\ttraining's auc: 0.880444\ttraining's binary_logloss: 0.200961\tvalid_1's auc: 0.792014\tvalid_1's binary_logloss: 0.233156\n",
      "[1500]\ttraining's auc: 0.882683\ttraining's binary_logloss: 0.199907\tvalid_1's auc: 0.791998\tvalid_1's binary_logloss: 0.233148\n",
      "[1550]\ttraining's auc: 0.88487\ttraining's binary_logloss: 0.198896\tvalid_1's auc: 0.792104\tvalid_1's binary_logloss: 0.233111\n",
      "[1600]\ttraining's auc: 0.887079\ttraining's binary_logloss: 0.197862\tvalid_1's auc: 0.792128\tvalid_1's binary_logloss: 0.233101\n",
      "[1650]\ttraining's auc: 0.889127\ttraining's binary_logloss: 0.196876\tvalid_1's auc: 0.79218\tvalid_1's binary_logloss: 0.233084\n",
      "[1700]\ttraining's auc: 0.891237\ttraining's binary_logloss: 0.195893\tvalid_1's auc: 0.792121\tvalid_1's binary_logloss: 0.23311\n",
      "[1750]\ttraining's auc: 0.893168\ttraining's binary_logloss: 0.194925\tvalid_1's auc: 0.792126\tvalid_1's binary_logloss: 0.233113\n",
      "[1800]\ttraining's auc: 0.895129\ttraining's binary_logloss: 0.193975\tvalid_1's auc: 0.792231\tvalid_1's binary_logloss: 0.233069\n",
      "[1850]\ttraining's auc: 0.897016\ttraining's binary_logloss: 0.193031\tvalid_1's auc: 0.79216\tvalid_1's binary_logloss: 0.233098\n",
      "[1900]\ttraining's auc: 0.898803\ttraining's binary_logloss: 0.192139\tvalid_1's auc: 0.792094\tvalid_1's binary_logloss: 0.233114\n",
      "[1950]\ttraining's auc: 0.900731\ttraining's binary_logloss: 0.19117\tvalid_1's auc: 0.792048\tvalid_1's binary_logloss: 0.233119\n",
      "[2000]\ttraining's auc: 0.902475\ttraining's binary_logloss: 0.190294\tvalid_1's auc: 0.791979\tvalid_1's binary_logloss: 0.233149\n",
      "Early stopping, best iteration is:\n",
      "[1804]\ttraining's auc: 0.895323\ttraining's binary_logloss: 0.193886\tvalid_1's auc: 0.792266\tvalid_1's binary_logloss: 0.233056\n"
     ]
    }
   ],
   "source": [
    "drop_importance = getDeleteFeature(5, df_train, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_pre = Pipeline(steps=[\n",
    "    ('app', appTrainTransformer()),\n",
    "    ('drop', dropTransformer(0.7)),\n",
    "    ('preprocesser', preprocesser),\n",
    "    ('importance drop', dropImportanceTransformer(drop_importance))\n",
    "])"
   ]
  },
  {
   "source": [
    "## 建造Pipeline"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class kfoldlgb(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, k):\n",
    "        self.k = k\n",
    "        self.clf = []\n",
    "        return None\n",
    " \n",
    "    def fit(self, X, y=None):\n",
    "        kf = KFold(n_splits=self.k)\n",
    "        for train_index, test_index in kf.split(X):\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "            gbm = lgb.LGBMClassifier(\n",
    "                nthread=4,\n",
    "                n_estimators=10000,\n",
    "                learning_rate=0.02,\n",
    "                num_leaves=34,\n",
    "                colsample_bytree=0.9497036,\n",
    "                subsample=0.8715623,\n",
    "                max_depth=8,\n",
    "                reg_alpha=0.041545473,\n",
    "                reg_lambda=0.0735294,\n",
    "                min_split_gain=0.0222415,\n",
    "                min_child_weight=39.3259775,\n",
    "                silent=-1,\n",
    "                verbose=-1, )\n",
    "            gbm.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_test, y_test)], eval_metric= 'auc', verbose= 50, early_stopping_rounds= 200)\n",
    "            self.clf.append(gbm)\n",
    "        return self\n",
    " \n",
    "    def predict_proba(self, X, y=None):\n",
    "        for i in range(self.k):\n",
    "            tmp = self.clf[i].predict_proba(X)\n",
    "            if i!=0:\n",
    "                result = result + tmp/self.k\n",
    "            else:\n",
    "                result = tmp/self.k\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(307511, 493)\n"
     ]
    }
   ],
   "source": [
    "app_av_train = app_train.copy()\n",
    "app_av_train = join(app_av_train)\n",
    "\n",
    "app_av_test = app_test.copy()\n",
    "app_av_test = join(app_av_test)\n",
    "\n",
    "app_pre_train = pipeline_pre.fit_transform(app_av_train)\n",
    "app_pre_test = pipeline_pre.transform(app_av_test)\n",
    "\n",
    "print(app_pre_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(48744, 493)\n"
     ]
    }
   ],
   "source": [
    "print(app_pre_test.shape)"
   ]
  },
  {
   "source": [
    "## Prediction"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "d_1's auc: 0.781667\tvalid_1's binary_logloss: 0.237073\n",
      "[500]\ttraining's auc: 0.828046\ttraining's binary_logloss: 0.22265\tvalid_1's auc: 0.782666\tvalid_1's binary_logloss: 0.236726\n",
      "[550]\ttraining's auc: 0.831941\ttraining's binary_logloss: 0.221106\tvalid_1's auc: 0.783421\tvalid_1's binary_logloss: 0.236501\n",
      "[600]\ttraining's auc: 0.835721\ttraining's binary_logloss: 0.219626\tvalid_1's auc: 0.784179\tvalid_1's binary_logloss: 0.236278\n",
      "[650]\ttraining's auc: 0.839022\ttraining's binary_logloss: 0.218288\tvalid_1's auc: 0.784574\tvalid_1's binary_logloss: 0.236139\n",
      "[700]\ttraining's auc: 0.842306\ttraining's binary_logloss: 0.216966\tvalid_1's auc: 0.785035\tvalid_1's binary_logloss: 0.235998\n",
      "[750]\ttraining's auc: 0.845696\ttraining's binary_logloss: 0.215604\tvalid_1's auc: 0.785401\tvalid_1's binary_logloss: 0.235873\n",
      "[800]\ttraining's auc: 0.848826\ttraining's binary_logloss: 0.214325\tvalid_1's auc: 0.785798\tvalid_1's binary_logloss: 0.235746\n",
      "[850]\ttraining's auc: 0.851673\ttraining's binary_logloss: 0.21313\tvalid_1's auc: 0.786115\tvalid_1's binary_logloss: 0.235645\n",
      "[900]\ttraining's auc: 0.8546\ttraining's binary_logloss: 0.211939\tvalid_1's auc: 0.786292\tvalid_1's binary_logloss: 0.235581\n",
      "[950]\ttraining's auc: 0.857723\ttraining's binary_logloss: 0.210654\tvalid_1's auc: 0.786482\tvalid_1's binary_logloss: 0.235532\n",
      "[1000]\ttraining's auc: 0.860511\ttraining's binary_logloss: 0.209498\tvalid_1's auc: 0.786747\tvalid_1's binary_logloss: 0.235485\n",
      "[1050]\ttraining's auc: 0.86305\ttraining's binary_logloss: 0.208394\tvalid_1's auc: 0.786953\tvalid_1's binary_logloss: 0.235416\n",
      "[1100]\ttraining's auc: 0.865633\ttraining's binary_logloss: 0.207275\tvalid_1's auc: 0.78721\tvalid_1's binary_logloss: 0.235344\n",
      "[1150]\ttraining's auc: 0.868065\ttraining's binary_logloss: 0.206183\tvalid_1's auc: 0.787268\tvalid_1's binary_logloss: 0.235321\n",
      "[1200]\ttraining's auc: 0.870492\ttraining's binary_logloss: 0.205121\tvalid_1's auc: 0.787363\tvalid_1's binary_logloss: 0.235293\n",
      "[1250]\ttraining's auc: 0.872811\ttraining's binary_logloss: 0.204072\tvalid_1's auc: 0.78742\tvalid_1's binary_logloss: 0.235272\n",
      "[1300]\ttraining's auc: 0.875222\ttraining's binary_logloss: 0.202983\tvalid_1's auc: 0.787563\tvalid_1's binary_logloss: 0.235227\n",
      "[1350]\ttraining's auc: 0.877513\ttraining's binary_logloss: 0.201932\tvalid_1's auc: 0.787721\tvalid_1's binary_logloss: 0.235185\n",
      "[1400]\ttraining's auc: 0.87965\ttraining's binary_logloss: 0.200932\tvalid_1's auc: 0.787769\tvalid_1's binary_logloss: 0.235171\n",
      "[1450]\ttraining's auc: 0.882008\ttraining's binary_logloss: 0.199852\tvalid_1's auc: 0.787813\tvalid_1's binary_logloss: 0.235167\n",
      "[1500]\ttraining's auc: 0.884016\ttraining's binary_logloss: 0.1989\tvalid_1's auc: 0.787816\tvalid_1's binary_logloss: 0.235159\n",
      "[1550]\ttraining's auc: 0.88632\ttraining's binary_logloss: 0.197839\tvalid_1's auc: 0.787899\tvalid_1's binary_logloss: 0.235141\n",
      "[1600]\ttraining's auc: 0.888382\ttraining's binary_logloss: 0.196827\tvalid_1's auc: 0.787984\tvalid_1's binary_logloss: 0.23514\n",
      "[1650]\ttraining's auc: 0.890531\ttraining's binary_logloss: 0.195804\tvalid_1's auc: 0.787912\tvalid_1's binary_logloss: 0.235167\n",
      "[1700]\ttraining's auc: 0.892588\ttraining's binary_logloss: 0.194796\tvalid_1's auc: 0.787928\tvalid_1's binary_logloss: 0.23517\n",
      "Early stopping, best iteration is:\n",
      "[1547]\ttraining's auc: 0.886177\ttraining's binary_logloss: 0.197913\tvalid_1's auc: 0.787946\tvalid_1's binary_logloss: 0.235127\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\ttraining's auc: 0.756654\ttraining's binary_logloss: 0.251775\tvalid_1's auc: 0.744854\tvalid_1's binary_logloss: 0.259454\n",
      "[100]\ttraining's auc: 0.772879\ttraining's binary_logloss: 0.243278\tvalid_1's auc: 0.757377\tvalid_1's binary_logloss: 0.25256\n",
      "[150]\ttraining's auc: 0.785449\ttraining's binary_logloss: 0.238139\tvalid_1's auc: 0.767146\tvalid_1's binary_logloss: 0.248789\n",
      "[200]\ttraining's auc: 0.794798\ttraining's binary_logloss: 0.23442\tvalid_1's auc: 0.77302\tvalid_1's binary_logloss: 0.24656\n",
      "[250]\ttraining's auc: 0.802291\ttraining's binary_logloss: 0.231455\tvalid_1's auc: 0.777352\tvalid_1's binary_logloss: 0.244941\n",
      "[300]\ttraining's auc: 0.808463\ttraining's binary_logloss: 0.228988\tvalid_1's auc: 0.780548\tvalid_1's binary_logloss: 0.243779\n",
      "[350]\ttraining's auc: 0.813856\ttraining's binary_logloss: 0.226847\tvalid_1's auc: 0.782789\tvalid_1's binary_logloss: 0.24296\n",
      "[400]\ttraining's auc: 0.818941\ttraining's binary_logloss: 0.2249\tvalid_1's auc: 0.784503\tvalid_1's binary_logloss: 0.24232\n",
      "[450]\ttraining's auc: 0.823385\ttraining's binary_logloss: 0.223116\tvalid_1's auc: 0.785838\tvalid_1's binary_logloss: 0.241834\n",
      "[500]\ttraining's auc: 0.827607\ttraining's binary_logloss: 0.221487\tvalid_1's auc: 0.786935\tvalid_1's binary_logloss: 0.241462\n",
      "[550]\ttraining's auc: 0.83144\ttraining's binary_logloss: 0.22\tvalid_1's auc: 0.787912\tvalid_1's binary_logloss: 0.241135\n",
      "[600]\ttraining's auc: 0.835052\ttraining's binary_logloss: 0.218571\tvalid_1's auc: 0.788457\tvalid_1's binary_logloss: 0.240928\n",
      "[650]\ttraining's auc: 0.838656\ttraining's binary_logloss: 0.217156\tvalid_1's auc: 0.789102\tvalid_1's binary_logloss: 0.240704\n",
      "[700]\ttraining's auc: 0.841931\ttraining's binary_logloss: 0.215812\tvalid_1's auc: 0.789555\tvalid_1's binary_logloss: 0.240545\n",
      "[750]\ttraining's auc: 0.845154\ttraining's binary_logloss: 0.214517\tvalid_1's auc: 0.789952\tvalid_1's binary_logloss: 0.240409\n",
      "[800]\ttraining's auc: 0.848051\ttraining's binary_logloss: 0.213333\tvalid_1's auc: 0.790321\tvalid_1's binary_logloss: 0.240294\n",
      "[850]\ttraining's auc: 0.850886\ttraining's binary_logloss: 0.212149\tvalid_1's auc: 0.790569\tvalid_1's binary_logloss: 0.240194\n",
      "[900]\ttraining's auc: 0.853577\ttraining's binary_logloss: 0.211039\tvalid_1's auc: 0.790794\tvalid_1's binary_logloss: 0.240122\n",
      "[950]\ttraining's auc: 0.856426\ttraining's binary_logloss: 0.209877\tvalid_1's auc: 0.790981\tvalid_1's binary_logloss: 0.240057\n",
      "[1000]\ttraining's auc: 0.859204\ttraining's binary_logloss: 0.208695\tvalid_1's auc: 0.791153\tvalid_1's binary_logloss: 0.239996\n",
      "[1050]\ttraining's auc: 0.86173\ttraining's binary_logloss: 0.207633\tvalid_1's auc: 0.791236\tvalid_1's binary_logloss: 0.23997\n",
      "[1100]\ttraining's auc: 0.864329\ttraining's binary_logloss: 0.206542\tvalid_1's auc: 0.791415\tvalid_1's binary_logloss: 0.239914\n",
      "[1150]\ttraining's auc: 0.866781\ttraining's binary_logloss: 0.205472\tvalid_1's auc: 0.791568\tvalid_1's binary_logloss: 0.239864\n",
      "[1200]\ttraining's auc: 0.8692\ttraining's binary_logloss: 0.204414\tvalid_1's auc: 0.79181\tvalid_1's binary_logloss: 0.239804\n",
      "[1250]\ttraining's auc: 0.871633\ttraining's binary_logloss: 0.203318\tvalid_1's auc: 0.792002\tvalid_1's binary_logloss: 0.239741\n",
      "[1300]\ttraining's auc: 0.874027\ttraining's binary_logloss: 0.202304\tvalid_1's auc: 0.792132\tvalid_1's binary_logloss: 0.239703\n",
      "[1350]\ttraining's auc: 0.876394\ttraining's binary_logloss: 0.201259\tvalid_1's auc: 0.792256\tvalid_1's binary_logloss: 0.239657\n",
      "[1400]\ttraining's auc: 0.878642\ttraining's binary_logloss: 0.200235\tvalid_1's auc: 0.792373\tvalid_1's binary_logloss: 0.239615\n",
      "[1450]\ttraining's auc: 0.880845\ttraining's binary_logloss: 0.199231\tvalid_1's auc: 0.792418\tvalid_1's binary_logloss: 0.239597\n",
      "[1500]\ttraining's auc: 0.882979\ttraining's binary_logloss: 0.198235\tvalid_1's auc: 0.792431\tvalid_1's binary_logloss: 0.239585\n",
      "[1550]\ttraining's auc: 0.885044\ttraining's binary_logloss: 0.197236\tvalid_1's auc: 0.792364\tvalid_1's binary_logloss: 0.239612\n",
      "[1600]\ttraining's auc: 0.887067\ttraining's binary_logloss: 0.196282\tvalid_1's auc: 0.792348\tvalid_1's binary_logloss: 0.239634\n",
      "[1650]\ttraining's auc: 0.889213\ttraining's binary_logloss: 0.195284\tvalid_1's auc: 0.792293\tvalid_1's binary_logloss: 0.239653\n",
      "Early stopping, best iteration is:\n",
      "[1466]\ttraining's auc: 0.881564\ttraining's binary_logloss: 0.198906\tvalid_1's auc: 0.792463\tvalid_1's binary_logloss: 0.239578\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\ttraining's auc: 0.759297\ttraining's binary_logloss: 0.252194\tvalid_1's auc: 0.73792\tvalid_1's binary_logloss: 0.257024\n",
      "[100]\ttraining's auc: 0.774611\ttraining's binary_logloss: 0.243597\tvalid_1's auc: 0.749451\tvalid_1's binary_logloss: 0.250675\n",
      "[150]\ttraining's auc: 0.787073\ttraining's binary_logloss: 0.23843\tvalid_1's auc: 0.758312\tvalid_1's binary_logloss: 0.247391\n",
      "[200]\ttraining's auc: 0.796555\ttraining's binary_logloss: 0.234642\tvalid_1's auc: 0.764534\tvalid_1's binary_logloss: 0.245285\n",
      "[250]\ttraining's auc: 0.803801\ttraining's binary_logloss: 0.231687\tvalid_1's auc: 0.768253\tvalid_1's binary_logloss: 0.244007\n",
      "[300]\ttraining's auc: 0.809995\ttraining's binary_logloss: 0.229191\tvalid_1's auc: 0.771222\tvalid_1's binary_logloss: 0.243033\n",
      "[350]\ttraining's auc: 0.815268\ttraining's binary_logloss: 0.227053\tvalid_1's auc: 0.773475\tvalid_1's binary_logloss: 0.242289\n",
      "[400]\ttraining's auc: 0.820083\ttraining's binary_logloss: 0.22513\tvalid_1's auc: 0.775369\tvalid_1's binary_logloss: 0.241694\n",
      "[450]\ttraining's auc: 0.824486\ttraining's binary_logloss: 0.223375\tvalid_1's auc: 0.776778\tvalid_1's binary_logloss: 0.241238\n",
      "[500]\ttraining's auc: 0.828563\ttraining's binary_logloss: 0.221757\tvalid_1's auc: 0.777974\tvalid_1's binary_logloss: 0.240859\n",
      "[550]\ttraining's auc: 0.832372\ttraining's binary_logloss: 0.220248\tvalid_1's auc: 0.77872\tvalid_1's binary_logloss: 0.240615\n",
      "[600]\ttraining's auc: 0.835978\ttraining's binary_logloss: 0.218826\tvalid_1's auc: 0.779467\tvalid_1's binary_logloss: 0.240382\n",
      "[650]\ttraining's auc: 0.83924\ttraining's binary_logloss: 0.217493\tvalid_1's auc: 0.7801\tvalid_1's binary_logloss: 0.240176\n",
      "[700]\ttraining's auc: 0.842665\ttraining's binary_logloss: 0.216133\tvalid_1's auc: 0.780592\tvalid_1's binary_logloss: 0.240008\n",
      "[750]\ttraining's auc: 0.845927\ttraining's binary_logloss: 0.214806\tvalid_1's auc: 0.781264\tvalid_1's binary_logloss: 0.239791\n",
      "[800]\ttraining's auc: 0.849098\ttraining's binary_logloss: 0.213518\tvalid_1's auc: 0.781685\tvalid_1's binary_logloss: 0.239643\n",
      "[850]\ttraining's auc: 0.852114\ttraining's binary_logloss: 0.212277\tvalid_1's auc: 0.782033\tvalid_1's binary_logloss: 0.239523\n",
      "[900]\ttraining's auc: 0.855203\ttraining's binary_logloss: 0.21101\tvalid_1's auc: 0.78225\tvalid_1's binary_logloss: 0.239439\n",
      "[950]\ttraining's auc: 0.858116\ttraining's binary_logloss: 0.20979\tvalid_1's auc: 0.782429\tvalid_1's binary_logloss: 0.239391\n",
      "[1000]\ttraining's auc: 0.860757\ttraining's binary_logloss: 0.208625\tvalid_1's auc: 0.782577\tvalid_1's binary_logloss: 0.23934\n",
      "[1050]\ttraining's auc: 0.863407\ttraining's binary_logloss: 0.207461\tvalid_1's auc: 0.782735\tvalid_1's binary_logloss: 0.239281\n",
      "[1100]\ttraining's auc: 0.86611\ttraining's binary_logloss: 0.206302\tvalid_1's auc: 0.782888\tvalid_1's binary_logloss: 0.239229\n",
      "[1150]\ttraining's auc: 0.868658\ttraining's binary_logloss: 0.205147\tvalid_1's auc: 0.782897\tvalid_1's binary_logloss: 0.23924\n",
      "[1200]\ttraining's auc: 0.871126\ttraining's binary_logloss: 0.204047\tvalid_1's auc: 0.782898\tvalid_1's binary_logloss: 0.239249\n",
      "[1250]\ttraining's auc: 0.873454\ttraining's binary_logloss: 0.202997\tvalid_1's auc: 0.782997\tvalid_1's binary_logloss: 0.239221\n",
      "[1300]\ttraining's auc: 0.875875\ttraining's binary_logloss: 0.201893\tvalid_1's auc: 0.783031\tvalid_1's binary_logloss: 0.239213\n",
      "[1350]\ttraining's auc: 0.878198\ttraining's binary_logloss: 0.200846\tvalid_1's auc: 0.783131\tvalid_1's binary_logloss: 0.23919\n",
      "[1400]\ttraining's auc: 0.880572\ttraining's binary_logloss: 0.199737\tvalid_1's auc: 0.783039\tvalid_1's binary_logloss: 0.239224\n",
      "[1450]\ttraining's auc: 0.882683\ttraining's binary_logloss: 0.198739\tvalid_1's auc: 0.7831\tvalid_1's binary_logloss: 0.239215\n",
      "[1500]\ttraining's auc: 0.884885\ttraining's binary_logloss: 0.197719\tvalid_1's auc: 0.78302\tvalid_1's binary_logloss: 0.239246\n",
      "Early stopping, best iteration is:\n",
      "[1346]\ttraining's auc: 0.877978\ttraining's binary_logloss: 0.200939\tvalid_1's auc: 0.783146\tvalid_1's binary_logloss: 0.239187\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\ttraining's auc: 0.756697\ttraining's binary_logloss: 0.25318\tvalid_1's auc: 0.748261\tvalid_1's binary_logloss: 0.253904\n",
      "[100]\ttraining's auc: 0.772503\ttraining's binary_logloss: 0.244588\tvalid_1's auc: 0.759232\tvalid_1's binary_logloss: 0.247008\n",
      "[150]\ttraining's auc: 0.785147\ttraining's binary_logloss: 0.239427\tvalid_1's auc: 0.767769\tvalid_1's binary_logloss: 0.243479\n",
      "[200]\ttraining's auc: 0.794736\ttraining's binary_logloss: 0.235658\tvalid_1's auc: 0.77345\tvalid_1's binary_logloss: 0.241259\n",
      "[250]\ttraining's auc: 0.80237\ttraining's binary_logloss: 0.232628\tvalid_1's auc: 0.777315\tvalid_1's binary_logloss: 0.239737\n",
      "[300]\ttraining's auc: 0.80859\ttraining's binary_logloss: 0.230129\tvalid_1's auc: 0.779826\tvalid_1's binary_logloss: 0.238734\n",
      "[350]\ttraining's auc: 0.813848\ttraining's binary_logloss: 0.227985\tvalid_1's auc: 0.781716\tvalid_1's binary_logloss: 0.237969\n",
      "[400]\ttraining's auc: 0.818473\ttraining's binary_logloss: 0.226097\tvalid_1's auc: 0.783072\tvalid_1's binary_logloss: 0.237437\n",
      "[450]\ttraining's auc: 0.822765\ttraining's binary_logloss: 0.224375\tvalid_1's auc: 0.784293\tvalid_1's binary_logloss: 0.236997\n",
      "[500]\ttraining's auc: 0.826894\ttraining's binary_logloss: 0.222731\tvalid_1's auc: 0.785407\tvalid_1's binary_logloss: 0.236613\n",
      "[550]\ttraining's auc: 0.830945\ttraining's binary_logloss: 0.221179\tvalid_1's auc: 0.78617\tvalid_1's binary_logloss: 0.236344\n",
      "[600]\ttraining's auc: 0.834647\ttraining's binary_logloss: 0.219709\tvalid_1's auc: 0.78709\tvalid_1's binary_logloss: 0.236035\n",
      "[650]\ttraining's auc: 0.837999\ttraining's binary_logloss: 0.218367\tvalid_1's auc: 0.787686\tvalid_1's binary_logloss: 0.235831\n",
      "[700]\ttraining's auc: 0.841236\ttraining's binary_logloss: 0.217086\tvalid_1's auc: 0.788033\tvalid_1's binary_logloss: 0.235694\n",
      "[750]\ttraining's auc: 0.844345\ttraining's binary_logloss: 0.215826\tvalid_1's auc: 0.788361\tvalid_1's binary_logloss: 0.23558\n",
      "[800]\ttraining's auc: 0.847327\ttraining's binary_logloss: 0.214618\tvalid_1's auc: 0.788718\tvalid_1's binary_logloss: 0.235459\n",
      "[850]\ttraining's auc: 0.850156\ttraining's binary_logloss: 0.21343\tvalid_1's auc: 0.78894\tvalid_1's binary_logloss: 0.235386\n",
      "[900]\ttraining's auc: 0.852935\ttraining's binary_logloss: 0.212268\tvalid_1's auc: 0.789079\tvalid_1's binary_logloss: 0.235321\n",
      "[950]\ttraining's auc: 0.855975\ttraining's binary_logloss: 0.211045\tvalid_1's auc: 0.789298\tvalid_1's binary_logloss: 0.235251\n",
      "[1000]\ttraining's auc: 0.858746\ttraining's binary_logloss: 0.209869\tvalid_1's auc: 0.789427\tvalid_1's binary_logloss: 0.235211\n",
      "[1050]\ttraining's auc: 0.861325\ttraining's binary_logloss: 0.208779\tvalid_1's auc: 0.789541\tvalid_1's binary_logloss: 0.235174\n",
      "[1100]\ttraining's auc: 0.863984\ttraining's binary_logloss: 0.20763\tvalid_1's auc: 0.789808\tvalid_1's binary_logloss: 0.235092\n",
      "[1150]\ttraining's auc: 0.866215\ttraining's binary_logloss: 0.20661\tvalid_1's auc: 0.789925\tvalid_1's binary_logloss: 0.235045\n",
      "[1200]\ttraining's auc: 0.868652\ttraining's binary_logloss: 0.20552\tvalid_1's auc: 0.790034\tvalid_1's binary_logloss: 0.235017\n",
      "[1250]\ttraining's auc: 0.871095\ttraining's binary_logloss: 0.204449\tvalid_1's auc: 0.790143\tvalid_1's binary_logloss: 0.234962\n",
      "[1300]\ttraining's auc: 0.873443\ttraining's binary_logloss: 0.20338\tvalid_1's auc: 0.790122\tvalid_1's binary_logloss: 0.234964\n",
      "[1350]\ttraining's auc: 0.875707\ttraining's binary_logloss: 0.202355\tvalid_1's auc: 0.790133\tvalid_1's binary_logloss: 0.234968\n",
      "[1400]\ttraining's auc: 0.877848\ttraining's binary_logloss: 0.201346\tvalid_1's auc: 0.790126\tvalid_1's binary_logloss: 0.234975\n",
      "[1450]\ttraining's auc: 0.879877\ttraining's binary_logloss: 0.20039\tvalid_1's auc: 0.790113\tvalid_1's binary_logloss: 0.234993\n",
      "Early stopping, best iteration is:\n",
      "[1264]\ttraining's auc: 0.871773\ttraining's binary_logloss: 0.204148\tvalid_1's auc: 0.790161\tvalid_1's binary_logloss: 0.234948\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\ttraining's auc: 0.755882\ttraining's binary_logloss: 0.253739\tvalid_1's auc: 0.751568\tvalid_1's binary_logloss: 0.251864\n",
      "[100]\ttraining's auc: 0.771601\ttraining's binary_logloss: 0.245253\tvalid_1's auc: 0.762208\tvalid_1's binary_logloss: 0.244896\n",
      "[150]\ttraining's auc: 0.784594\ttraining's binary_logloss: 0.240033\tvalid_1's auc: 0.770902\tvalid_1's binary_logloss: 0.241249\n",
      "[200]\ttraining's auc: 0.794444\ttraining's binary_logloss: 0.236216\tvalid_1's auc: 0.77641\tvalid_1's binary_logloss: 0.239054\n",
      "[250]\ttraining's auc: 0.801944\ttraining's binary_logloss: 0.233186\tvalid_1's auc: 0.780363\tvalid_1's binary_logloss: 0.237513\n",
      "[300]\ttraining's auc: 0.808077\ttraining's binary_logloss: 0.230708\tvalid_1's auc: 0.782929\tvalid_1's binary_logloss: 0.236506\n",
      "[350]\ttraining's auc: 0.813506\ttraining's binary_logloss: 0.228543\tvalid_1's auc: 0.784731\tvalid_1's binary_logloss: 0.235775\n",
      "[400]\ttraining's auc: 0.818471\ttraining's binary_logloss: 0.226585\tvalid_1's auc: 0.786238\tvalid_1's binary_logloss: 0.235219\n",
      "[450]\ttraining's auc: 0.823025\ttraining's binary_logloss: 0.224801\tvalid_1's auc: 0.787385\tvalid_1's binary_logloss: 0.234816\n",
      "[500]\ttraining's auc: 0.827177\ttraining's binary_logloss: 0.223147\tvalid_1's auc: 0.788365\tvalid_1's binary_logloss: 0.234462\n",
      "[550]\ttraining's auc: 0.831324\ttraining's binary_logloss: 0.22153\tvalid_1's auc: 0.789116\tvalid_1's binary_logloss: 0.234187\n",
      "[600]\ttraining's auc: 0.83506\ttraining's binary_logloss: 0.220043\tvalid_1's auc: 0.789628\tvalid_1's binary_logloss: 0.233971\n",
      "[650]\ttraining's auc: 0.83848\ttraining's binary_logloss: 0.218692\tvalid_1's auc: 0.790154\tvalid_1's binary_logloss: 0.23379\n",
      "[700]\ttraining's auc: 0.841799\ttraining's binary_logloss: 0.217363\tvalid_1's auc: 0.79056\tvalid_1's binary_logloss: 0.233644\n",
      "[750]\ttraining's auc: 0.844756\ttraining's binary_logloss: 0.216172\tvalid_1's auc: 0.790793\tvalid_1's binary_logloss: 0.233543\n",
      "[800]\ttraining's auc: 0.847828\ttraining's binary_logloss: 0.214937\tvalid_1's auc: 0.791095\tvalid_1's binary_logloss: 0.233445\n",
      "[850]\ttraining's auc: 0.850755\ttraining's binary_logloss: 0.213762\tvalid_1's auc: 0.791452\tvalid_1's binary_logloss: 0.23332\n",
      "[900]\ttraining's auc: 0.853617\ttraining's binary_logloss: 0.212595\tvalid_1's auc: 0.791686\tvalid_1's binary_logloss: 0.233247\n",
      "[950]\ttraining's auc: 0.856287\ttraining's binary_logloss: 0.211462\tvalid_1's auc: 0.792101\tvalid_1's binary_logloss: 0.233126\n",
      "[1000]\ttraining's auc: 0.858994\ttraining's binary_logloss: 0.210339\tvalid_1's auc: 0.792347\tvalid_1's binary_logloss: 0.233052\n",
      "[1050]\ttraining's auc: 0.861628\ttraining's binary_logloss: 0.209237\tvalid_1's auc: 0.792519\tvalid_1's binary_logloss: 0.232985\n",
      "[1100]\ttraining's auc: 0.864034\ttraining's binary_logloss: 0.20819\tvalid_1's auc: 0.792631\tvalid_1's binary_logloss: 0.232935\n",
      "[1150]\ttraining's auc: 0.866537\ttraining's binary_logloss: 0.20709\tvalid_1's auc: 0.792631\tvalid_1's binary_logloss: 0.232924\n",
      "[1200]\ttraining's auc: 0.868997\ttraining's binary_logloss: 0.206015\tvalid_1's auc: 0.792648\tvalid_1's binary_logloss: 0.232919\n",
      "[1250]\ttraining's auc: 0.871396\ttraining's binary_logloss: 0.20495\tvalid_1's auc: 0.792698\tvalid_1's binary_logloss: 0.232907\n",
      "[1300]\ttraining's auc: 0.873746\ttraining's binary_logloss: 0.203903\tvalid_1's auc: 0.792693\tvalid_1's binary_logloss: 0.232901\n",
      "[1350]\ttraining's auc: 0.876014\ttraining's binary_logloss: 0.202891\tvalid_1's auc: 0.792759\tvalid_1's binary_logloss: 0.232869\n",
      "[1400]\ttraining's auc: 0.878247\ttraining's binary_logloss: 0.201896\tvalid_1's auc: 0.792821\tvalid_1's binary_logloss: 0.232839\n",
      "[1450]\ttraining's auc: 0.880506\ttraining's binary_logloss: 0.200861\tvalid_1's auc: 0.792947\tvalid_1's binary_logloss: 0.232808\n",
      "[1500]\ttraining's auc: 0.882794\ttraining's binary_logloss: 0.199805\tvalid_1's auc: 0.792865\tvalid_1's binary_logloss: 0.232832\n",
      "[1550]\ttraining's auc: 0.884858\ttraining's binary_logloss: 0.198819\tvalid_1's auc: 0.792913\tvalid_1's binary_logloss: 0.232817\n",
      "[1600]\ttraining's auc: 0.887024\ttraining's binary_logloss: 0.19779\tvalid_1's auc: 0.792851\tvalid_1's binary_logloss: 0.232841\n",
      "[1650]\ttraining's auc: 0.888956\ttraining's binary_logloss: 0.196858\tvalid_1's auc: 0.792883\tvalid_1's binary_logloss: 0.232829\n",
      "Early stopping, best iteration is:\n",
      "[1461]\ttraining's auc: 0.880975\ttraining's binary_logloss: 0.200628\tvalid_1's auc: 0.792986\tvalid_1's binary_logloss: 0.232792\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "kfoldlgb(k=5)"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "# 使用sklearn的pipelines训练一个模型\n",
    "clf = kfoldlgb(5)\n",
    "clf.fit(app_pre_train, train_labels)"
   ]
  },
  {
   "source": [
    "## Kaggle 输出 （用于上传） "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = clf.predict_proba(app_pre_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_pred = Y[:, 1]\n",
    "submit = app_test[['SK_ID_CURR']]\n",
    "submit['TARGET'] = log_reg_pred\n",
    "submit.to_csv('baseline.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\ttraining's auc: 0.756527\ttraining's binary_logloss: 0.253187\tvalid_1's auc: 0.742635\tvalid_1's binary_logloss: 0.254126\n",
      "[100]\ttraining's auc: 0.771622\ttraining's binary_logloss: 0.24485\tvalid_1's auc: 0.754413\tvalid_1's binary_logloss: 0.247331\n",
      "[150]\ttraining's auc: 0.783899\ttraining's binary_logloss: 0.239833\tvalid_1's auc: 0.762944\tvalid_1's binary_logloss: 0.243903\n",
      "[200]\ttraining's auc: 0.793094\ttraining's binary_logloss: 0.236199\tvalid_1's auc: 0.768879\tvalid_1's binary_logloss: 0.241818\n",
      "[250]\ttraining's auc: 0.800163\ttraining's binary_logloss: 0.233333\tvalid_1's auc: 0.773119\tvalid_1's binary_logloss: 0.240311\n",
      "[300]\ttraining's auc: 0.806085\ttraining's binary_logloss: 0.230945\tvalid_1's auc: 0.776399\tvalid_1's binary_logloss: 0.239237\n",
      "[350]\ttraining's auc: 0.811301\ttraining's binary_logloss: 0.228879\tvalid_1's auc: 0.778535\tvalid_1's binary_logloss: 0.238514\n",
      "[400]\ttraining's auc: 0.81586\ttraining's binary_logloss: 0.227077\tvalid_1's auc: 0.780202\tvalid_1's binary_logloss: 0.237948\n",
      "[450]\ttraining's auc: 0.820299\ttraining's binary_logloss: 0.225352\tvalid_1's auc: 0.78165\tvalid_1's binary_logloss: 0.237473\n",
      "[500]\ttraining's auc: 0.824214\ttraining's binary_logloss: 0.223815\tvalid_1's auc: 0.782863\tvalid_1's binary_logloss: 0.23707\n",
      "[550]\ttraining's auc: 0.828054\ttraining's binary_logloss: 0.222337\tvalid_1's auc: 0.783732\tvalid_1's binary_logloss: 0.236802\n",
      "[600]\ttraining's auc: 0.831474\ttraining's binary_logloss: 0.220971\tvalid_1's auc: 0.784435\tvalid_1's binary_logloss: 0.236568\n",
      "[650]\ttraining's auc: 0.834878\ttraining's binary_logloss: 0.219643\tvalid_1's auc: 0.784973\tvalid_1's binary_logloss: 0.236406\n",
      "[700]\ttraining's auc: 0.838039\ttraining's binary_logloss: 0.218385\tvalid_1's auc: 0.785281\tvalid_1's binary_logloss: 0.23631\n",
      "[750]\ttraining's auc: 0.841191\ttraining's binary_logloss: 0.217127\tvalid_1's auc: 0.785567\tvalid_1's binary_logloss: 0.236176\n",
      "[800]\ttraining's auc: 0.84401\ttraining's binary_logloss: 0.21597\tvalid_1's auc: 0.785846\tvalid_1's binary_logloss: 0.236079\n",
      "[850]\ttraining's auc: 0.846663\ttraining's binary_logloss: 0.214873\tvalid_1's auc: 0.786171\tvalid_1's binary_logloss: 0.235966\n",
      "[900]\ttraining's auc: 0.849245\ttraining's binary_logloss: 0.213783\tvalid_1's auc: 0.786464\tvalid_1's binary_logloss: 0.235884\n",
      "[950]\ttraining's auc: 0.851822\ttraining's binary_logloss: 0.212719\tvalid_1's auc: 0.7866\tvalid_1's binary_logloss: 0.235839\n",
      "[1000]\ttraining's auc: 0.854336\ttraining's binary_logloss: 0.211675\tvalid_1's auc: 0.78688\tvalid_1's binary_logloss: 0.235759\n",
      "[1050]\ttraining's auc: 0.856687\ttraining's binary_logloss: 0.210649\tvalid_1's auc: 0.787066\tvalid_1's binary_logloss: 0.235681\n",
      "[1100]\ttraining's auc: 0.859073\ttraining's binary_logloss: 0.209638\tvalid_1's auc: 0.78705\tvalid_1's binary_logloss: 0.235688\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-081fe79e0238>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 使用sklearn的pipelines训练一个模型\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkfoldlgb\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapp_pre_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapp_pre_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mlog_reg_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-44b72fe252ed>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     24\u001b[0m                 \u001b[0msilent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m                 verbose=-1, )\n\u001b[1;32m---> 26\u001b[1;33m             \u001b[0mgbm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_set\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_metric\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;34m'auc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m200\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgbm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\creditRisk\\lib\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[0;32m    798\u001b[0m                                         \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    799\u001b[0m                                         \u001b[0mcategorical_feature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 800\u001b[1;33m                                         callbacks=callbacks)\n\u001b[0m\u001b[0;32m    801\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    802\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\creditRisk\\lib\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[0;32m    593\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    594\u001b[0m                               \u001b[0mcategorical_feature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 595\u001b[1;33m                               callbacks=callbacks)\n\u001b[0m\u001b[0;32m    596\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\creditRisk\\lib\\site-packages\\lightgbm\\engine.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    247\u001b[0m                                     evaluation_result_list=None))\n\u001b[0;32m    248\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 249\u001b[1;33m         \u001b[0mbooster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    250\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\creditRisk\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, train_set, fobj)\u001b[0m\n\u001b[0;32m   1924\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[0;32m   1925\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1926\u001b[1;33m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[0;32m   1927\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mFalse\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1928\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# 使用sklearn的pipelines训练一个模型\n",
    "clf = kfoldlgb(10)\n",
    "clf.fit(app_pre_train, train_labels)\n",
    "Y = clf.predict_proba(app_pre_test)\n",
    "log_reg_pred = Y[:, 1]\n",
    "submit = app_test[['SK_ID_CURR']]\n",
    "submit['TARGET'] = log_reg_pred\n",
    "submit.to_csv('baseline1.csv', index = False)"
   ]
  },
  {
   "source": [
    "## Pipeline Output"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['./preprocess_model.joblib']"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "joblib.dump(pipeline_pre, './preprocess_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(clf, './clf.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('creditRisk': conda)",
   "metadata": {
    "interpreter": {
     "hash": "e1c47dc2f2d2db03ac4d3dd10e2c82551458f1f333f769c0a113c39f6515fc6b"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}